{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73c7c97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gc\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW\n",
    "from tqdm import tqdm\n",
    "import scml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6602a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "scml.seed_everything()\n",
    "seed = 31\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e7c08c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='pretrained/google/electra-small-discriminator', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "pretrained_dir = \"pretrained/google/electra-small-discriminator\"\n",
    "model_max_length = 512\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_dir, model_max_length=model_max_length)\n",
    "print(f\"{repr(tokenizer)}\\n{tokenizer.model_input_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6ade8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pretrained/google/electra-small-discriminator were not used when initializing ElectraForQuestionAnswering: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at pretrained/google/electra-small-discriminator and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraConfig {\n",
      "  \"_name_or_path\": \"pretrained/google/electra-small-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.5.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(pretrained_dir)\n",
    "print(repr(model.config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c1aee2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25200 entries, 353847 to 182649\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Id                    25200 non-null  object\n",
      " 1   is_multi              25200 non-null  int8  \n",
      " 2   ground_truth          25200 non-null  object\n",
      " 3   dataset_labels        25200 non-null  object\n",
      " 4   is_impossible         25200 non-null  int8  \n",
      " 5   answer_start          25200 non-null  int16 \n",
      " 6   answer_end            25200 non-null  int16 \n",
      " 7   context               25200 non-null  object\n",
      " 8   context_token_length  25200 non-null  int16 \n",
      "dtypes: int16(3), int8(2), object(4)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet(\"input/train.parquet\")\n",
    "train = train.sample(frac=0.07)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34457e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "len=25200\n",
      "CPU times: user 24.1 s, sys: 2.91 s, total: 27 s\n",
      "Wall time: 6.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"what dataset\"\n",
    "questions = [question] * len(train)\n",
    "enc = tokenizer(list(train[\"context\"]), questions, padding=\"max_length\")\n",
    "print(f\"{repr(enc.keys())}\\nlen={len(enc['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f02a2570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_positions(encodings, answer_start, answer_end, ids, is_impossible):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(is_impossible)):\n",
    "        j, k = 0, 0\n",
    "        if is_impossible[i] == 0:\n",
    "            j = encodings.char_to_token(i, answer_start[i])\n",
    "            if j is None:\n",
    "                #offsets = encodings[\"offset_mapping\"][i]\n",
    "                _id = ids[i]\n",
    "                raise ValueError(f\"start pos must not be None. i={i}, id={_id}, answer_start={answer_start[i]}\")  #offsets={offsets}\") \n",
    "            k = encodings.char_to_token(i, answer_end[i] - 1)\n",
    "            if k is None:\n",
    "                raise ValueError(\"end pos must not be None\")\n",
    "            if j > k:\n",
    "                raise ValueError(\"start pos must be less than or equals end pos\")\n",
    "        start_positions.append(j)\n",
    "        end_positions.append(k)\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f7847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3170c5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.2 ms, sys: 0 ns, total: 31.2 ms\n",
      "Wall time: 39.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "add_token_positions(\n",
    "    enc, \n",
    "    answer_start=list(train[\"answer_start\"]), \n",
    "    answer_end=list(train[\"answer_end\"]),\n",
    "    ids=list(train[\"Id\"]),\n",
    "    is_impossible=list(train[\"is_impossible\"]),\n",
    ")\n",
    "train_ds = MyDataset(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef07e6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del enc, questions\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "813f9edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [10:46:02<00:00, 196.76s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=0.6631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "#lr=5e-4\n",
    "optim = AdamW(model.parameters(), lr=1e-3)\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    loss_mean = 0\n",
    "    steps = len(train_loader)\n",
    "    for batch in tqdm(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        outputs = model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask,\n",
    "                        start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs[0]\n",
    "        loss_mean += loss / steps\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    print(f\"epoch={epoch}, loss={loss_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cefc2e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForQuestionAnswering(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70552291",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9916f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('output/tokenizer_config.json',\n",
       " 'output/special_tokens_map.json',\n",
       " 'output/vocab.txt',\n",
       " 'output/added_tokens.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d20ffc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraConfig {\n",
      "  \"_name_or_path\": \"output\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.5.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(\"output\")\n",
    "print(repr(model.config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77d3247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.sample(30)\n",
    "questions = [question] * 30\n",
    "contexts = list(df[\"context\"])\n",
    "golds = list(df[\"dataset_labels\"])\n",
    "is_impossible = list(df[\"is_impossible\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c6b6f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=what dataset\n",
      "c=ell-established relationship between the paramagnetic properties of unbound iron and its impact on T2* image susceptibility. This general property of susceptibility is fundamental to imaging protocols designed to measure tissue iron levels 5, 28, 29 , as well as fMRI 30, 31 . A typical approach to quantitative iron imaging involves the collection of structural T2-or T2*-weighted images at varying delays in echo time (TE). Higher regional brain iron levels increase regional susceptibility, and therefore the rate at which the signal decays over time. It is then possible to fit a decay function to quantify iron content at each voxel [32] [33] [34] . Similarly, fMRI sequences capitalize on the fact that deoxygenated blood is paramagnetic and increases the rate of signal decay, much like unbound iron, while oxygenated blood is moderately diamagnetic and has the effect of slowing the rate of signal decay 35 . However, standard fMRI sequences use a fixed TE that optimally distinguishes oxygenated vs. deoxygenated blood levels (i.e., blood oxygen level dependent, or BOLD signal). fMRI sequences only collect a single TE, and therefore cannot be used to estimate a decay function at each voxel. However, they are, by design, sensitive to variations in magnetic susceptibility such as those caused by variations in brain iron. Although it is not possible to estimate absolute iron content from a susceptibility image with a single TE, it may be possible to provide an estimate of the relative iron content at each voxel, particularly for regions that are high in iron content such as the striatum. As an example, Figure 1 , top, demonstrates how the signal in a susceptibility weighted image might decay given different levels of iron when sampled at 7 different echo times; these values would be fit to an exponential decay function; the reciprocal of this fit is linearly related to iron content (e.g., 1/T2=R2; 1/T2*=R2*). Figure 1 , bottom, illustrates how those same decay curves might be\n",
      "i=0, j=0, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=ADNI\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=what dataset\n",
      "c=ditional barriers erected between the four disciplines by integrating them into one cohesive teaching and learning paradigm helping students make connections between school, community, work, and the global world (Lantz, Jr., 2009) . Thus, STEM education is a priority not only because we need today's students to become tomorrow's leaders in innovation and help the US economy, but also to increase STEM interest and skill.\n",
      "Career and Technical Education (CTE) curricular options play a critical role in preparing individuals for the world of work. CTE offers a holistic education that is dynamic, flexible, and responsive to the ever-changing needs and advances of technology, education, the workforce, and the economy. CTE incorporates innovative methods, ideas, and resources that provide students with a range of skills necessary to be considered workforce ready and secure meaningful work (Bray, Luzzo, Green, Gore, Katt, & Harrington, 2008) .\n",
      "One curricular option that has gained momentum within the field of CTE is the linking of technology education programs with engineering preparation programs. The field of technology education has edged closer to infusing aspects of engineering design into the curriculum.\n",
      "To further complement these efforts, professional bodies and organizations that are affiliated to CTE and workforce preparation have renamed themselves and retooled their missions and goals. Consider the following trends:\n",
      "1. Herschbach (2009) noted that in contemporary school curriculums at all instructional levels and particularly at the middle and high school levels, the term engineering has found its way into course descriptions in one form or another. According to Gattie and Wicklein (2007) , an engineering perspective emphasis provides a vehicle to, (a) increase interest and improve competence in mathematics and science among CTE students by providing an arena for synthesizing mathematics and science principles and (b) improve technological literacy by exposing st\n",
      "i=1, j=0, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=National Assessment of Education Progress\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=what dataset\n",
      "c=is to calculate the cumulative number of cases for Utah, while allowing non-consecutive zero entries at the beginning of the spread. We first start with reported data (i.e., the cumulative daily sum of new cases from March 4th through April 4th in Utah, as reported by Utah Department of Health), and then end with the predicted data based on step-II (i.e., the continued cumulative daily sum of new cases from 5 April through 28 April based on the South Korea model and 24 April based on the Italy model. (4) The fourth step of the forecast is to fit a log-logistic model with four-parameters [9] [10] [11] for the cumulative number of cases, \n",
      "We followed five steps to build the forecast model: (1) determine how many days Utah is behind South Korea and Italy in reporting new cases. For example, many experts report that the U.S. is between one and two weeks behind Italy. In our approach, to align the start date of the pandemic in Utah relative to South Korea and Italy, we overlapped the first seven consecutive days with non-zero cases in Utah (starting on 11 March) with that in South Korea (16 February) and Italy (20 February) (see Table 1 ). Thus, Utah lags behind South Korea and Italy by 24 and 20 days, respectively. (2) The second step of the forecast is to predict the number of new cases in Utah, for a number of days into the future that is equal to the number of days representing the lag between Utah and South Korea or Italy based on each country's actual daily spread rates. Spread rates are calculated as the relative change in the number of new cases between two consecutive days. A list of the needed daily spread rates required for predicting new cases in Utah for the next 24 (South Korea) and 20 (Italy) days, is shown in Table 1 . Since the actual daily spread rate is the relative change in new cases between two consecutive days by construction, it could be viewed in the sense of the Markovian property [8] as the number of cases tomorrow are assumed to depend only on\n",
      "i=2, j=0, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=Our World in Data\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=what dataset\n",
      "c=of variance (ANOVA) with a group as a element (3 groups: NC, EMCI, LMCI) after age and gender effects were regressed out by using a linear regression model. The statistical significance was P < 0.05.\n",
      "In three groups, considering that we implemented many times comparisons, we performed a 10,000 times random arrangement to test whether the identified altered connections are really significant. For the sake of getting a statistically significant difference, post-hoc in each two groups have been performed between the NC and EMCI, NC and LMCI, EMCI and LMCI (P < 0.05). To explore the relationship between functional connectivity and cognitive ability, we also computed the Pearson's correlations between the Z scores and the MMSE scores at each level in the EMCI, and LMCI group. For each group, a 246  246 functional connectivity matrix was computed. At node level, significant differences between groups were detected, and these differences were widely separated in several RSNs. (1) Compared with EMCI group and LMCI group (Fig. 1) , significant decrease integrity was showed in two regions of Posterior Salience Network (PCL_R_2_1, INS_R_6_1), and two regions of Language Network (pSTS_L_2_2, MTG_L_4_3), and two regions of dorsal Default Mode Network (CG_L_7_1, CG_L_7_6). (2) Compared with EMCI group and NC group (Fig. 2) , significant decrease integrity was showed in the region of Dorsal Default Mode Network (Hipp_L_2_1). (3) Compared with LMCI group and NC group (Fig. 3) , significant decrease integrity was showed in five regions of dorsal Default Mode Network (CG_L_7_6, CG_L_7_1, SFG_L_7_7, IPL_L_6_5, Hipp_L_2_1), and one region of Anterior Salience Network (IFG_R_6_3), three regions of Language Network (IFG_L_6_3, pSTS_L_2_2, MTG_L_4_3), one region of Posterior Salience Network \n",
      "i=3, j=0, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=ADNI\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=what dataset\n",
      "c=ange (15, 16) , although some have also looked at hippocampal volume change (17, 18) . In these studies, despite the known regional specificity of AD-related volumetric changes, global measures have shown greater sensitivity than local measurements, possibly because of the difficulty in obtaining accurate measurement of local brain structure change using existing methods (17) . Nevertheless, these global measures of brain structure change are highly correlated with gold-standard clinical outcome measures, such as the Clinical Dementia Rating Scale Sum of Boxes and Mini Mental State Examination scores (15, 19) .\n",
      "The use of longitudinal anatomical quantification in multicenter clinical trials presents a number of challenges, including differences in MRI pulse sequences across scanner manufacturers, scannerspecific spatial distortions, and changes in scanner hardware and software over time that can affect image properties. In view of this, the Alzheimer's Disease Neuroimaging Initiative (ADNI) was designed to validate and compare imaging and biofluid markers of disease progression in a realistic multicenter clinical trial setting (20) . The large, publicly available ADNI database thus provides a realistic setting in which to validate imaging methods aimed at assessing AD pathology. To this database, we applied a recently developed method for obtaining precise measures of interval change in cortical and subcortical regions, based on structural MRI, and determined the relative statistical power to discriminate pathology afforded by different regional measures. We examined two models of treatable effects for power calculations. The first, Model T (for ''total''), assumes that the study drug modifies both disease-and aging-related changes; the second, Model D (for ''disease-specific''), assumes that the study drug modifies AD-or mild cognitive impairment-(MCI) related changes but has no effect on aging-related changes. We found that multiple regional volume changes, including \n",
      "i=4, j=187, k=189\n",
      "a=adni\n",
      "g=ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=what dataset\n",
      "c=e of Genomic Variants (DGV) (http://projects.tcag.ca/variation/). DGV was created in 2004 and provides a useful catalogue of control data for studies aiming at correlating genomic variations with phenotypic data. It is freely accessible and is continuously updated with new high quality data, including samples analyzed in different studies. DGV contains a summary of genomic alterations involving segments greater than 50 bp and less than 3 Mb. A new version of DGV in which the majority of CNVs were detected by NGS platforms and methods has been recently developed. Zarrei et al. [71] considered recent high-resolution studies that maximize sensitivity and minimize false discoveries. In the new version, uncertain results from previous studies have been removed. They include CNVs detected from platforms such as BAC array, which overestimate the breakpoints [72] , have low resolution, and miss many small variants. Some individual CNVs were removed since previous studies had stated that they were very rare or due to false discoveries. In the new DGV version, Zarrei et al. have also combined the variants of different studies in merged CNVRs (copy number variation regions) and used a CNVR-clustering algorithm to identify groups of variants that have at least 50% of reciprocal overlaps [40] .\n",
      "Other Other tools are often adopted for obtaining information related to genes included in detected CNVs. Diagnostic laboratories primarily use UCSC Genome Browser (http://genome.ucsc.edu/) since it enables connection to various databases described above [73] . To improve the classification of CNVs, analytical tools are employed. One of the most common is Genomic Classification of CNVs Objectively (GECCO) (http://sourceforge.net/projects/genomege cco/) that includes functionalities for analyzing genomic characteristics as repetitive elements inside CNVs and aids in confirming the pathogenicity of de novo CNVs. Several authors have performed studies to identify the potential role of CNVs i\n",
      "i=5, j=0, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=what dataset\n",
      "c=ion by dissolving hemin powder in 1 M NaOH with gentle stirring for 2 h, and then filtering through a Whatman #1 filter followed by storage at 4 C. The concentration of the hematin solution was determined from the extinction coefficient of the monomer absorption maxima (385 nm) of 5840 M 1 cm 1 [34] , and remained stable for a period of at least 4 months.\n",
      "The coded ADNI serum samples (0.5 ml) were thawed and divided equally into two aliquots. Immediately before hemin treatment of the serum either hematin in 1 M NaOH or 1 M control NaOH solution were slowly added to stirred buffers containing 20 mM Tris, 151 mM NaC1, 3 mM NaN 3 (TBS), pH 7.8. The final pH of the hemin or control buffers was adjusted to 7.8 and 0.1 ml aliquots of thawed serum samples were mixed with 0.9 ml of hemin and control buffer. The samples were incubated for 20 h on a rocking platform at 36C then stored at 80 C until ELISA analysis.\n",
      "Follow-up study-Based on the encouraging results obtained in the pilot study, the ADNI provided samples for a follow-up study (vide infra). During the period between these studies, we had the opportunity to more carefully evaluate protocols and methods to optimize conditions for processing serum samples for R-RAA aPL analysis. A more pure source of hemin (99%, Frontier Scientific, Logan, UT) replaced the Sigma product used in the pilot studies. With each change in methodology, bridging studies using a set of serum samples from five HC donors frozen in multiple aliquots were used to determine the rank order OD output in each aPL ELISA assay. The R-RAA preparation protocol previously described [35] was used with modifications.\n",
      "Aliquots of the 90 ADNI serum samples were thawed and treated with Cleanascite TM (Biotech Support Group, Inc., North Brunswick, NJ) at a serum: Cleanascite TM ratio of 4:1 v/v in 2 ml micro centrifuge tubes with gentle rocking at 37 C for 10 min followed by centrifugation for 1 min at 16 000 g. Treatment with Cleanascite TM removes lipoproteins fro\n",
      "i=6, j=87, k=89\n",
      "a=adni\n",
      "g=ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=what dataset\n",
      "c= occupational attainments) between men and women have been considered as candidate causal factors [Mielke et al., 2014] . Notably, a study on post mortem specimen by Barnes et al. [2005] showed that the link between neuropathology and its clinical expression is stronger in women as compared to men. Specifically, they found that for every unit increase in pathology, women were significantly more likely to show clinical dementia (Odds-ratio: 22.67) as compared to men (Odds-ratio: 2.82) [Barnes et al., 2005] . Neuroimaging studies have also shown gender differences in AD-related neuropathology. Rowe et al. reported higher amyloid load (as assessed by PET with Pittsburgh compound B (PiB)) in AD males than in females with comparable cognitive impairment [Rowe et al., 2010] .\n",
      "Overall, these findings suggest that, although AD-related brain changes are more severe in men [Perneczky et al., 2007; Rowe et al. 2010] , women are more likely to express these as clinical dementia [Barnes et al., 2005] , and these findings might be crucially related to a lower or different amount of CR.\n",
      "Considering the above very limited reports on gender differences both in healthy aging and AD brain we investigated in a large dataset of healthy elderly subjects (HE) and AD patients, whether differences exist between males and females in brain metabolic activity, also including the effects of education and occupation. In addition, we also assessed brain metaboli connectivity in the main resting-state functional networks (i.e., the Default Mode Network [DMN] , the frontal executive control network [ECN] , and the Language network [LN] ), an approach never previously applied to explore gender differences in aging and dementia. This investigation might add important knowledge in the gender neurobiology of brain aging and AD dementia.   Two hundred and twenty-five HE (115 males and 110 females) were selected for this study from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. The ADNI\n",
      "i=7, j=431, k=433\n",
      "a=adni\n",
      "g=ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=what dataset\n",
      "c=ADNI database, Thompson and Holland (2011) noted an unexplained and surprising jump in the time-series of changes. We were able to replicate this effect in our own data, and the graph is shown in Fig. 1 . Clearly there is an apparent jump in the atrophy rate between 0 and 6 months, with more linear changes thereafter. The jump occurs in all diagnostic groups -AD, MCI, and controls. In Hua et al. (2010) , we showed time-series of cumulative atrophy in MCI and AD. This jump is more coherent with the rest of the trajectory in those groups, and we interpreted it as natural. This was plausible, given the possibility of a biological nonlinear change in the atrophy over time due to changes in the disease process, measurement error, drift in scanner calibration over time and attrition or sampling effects. However, when the trajectory of atrophy from controls is also shown, it becomes clear that there is a systematic bias in the measures of unknown origin. We were alerted to this effect on September 27, 2010 (W. Thompson, personal communication) and conducted a set of experiments that hypothesized, tested, identified and subsequently corrected the source of this problem. We postulate that any bias in atrophy estimates may be comprised of a constant, additive offset, and a component whose magnitude may depend on the true level of atrophy, an atrophy-dependent component. We report our experiments below, which consider factors that might affect the linearity of the time-series. In turn, we discuss various sources of bias as they are relevant to ongoing investigations of brain morphometry by our group and others.\n",
      "1. Inverse-consistency. In Hua et al. (2010) , we computed atrophy rates using a registration method developed and validated in Yanovsky et al. (2009) . This approach estimates the rate of brain change by computing a deformation field that optimizes a matching cost functional, in this case the mutual information (MI) between the deforming image and the target scan, whil\n",
      "i=8, j=1, k=3\n",
      "a=adni\n",
      "g=ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=what dataset\n",
      "c=s was 177, 155, 136, and 125 for continuous no-till, conservation crop rotations, cover crops, and variable-rate application of inputs, respectively. Summary data for the dependent and independent variables are presented in Tables 1-3. The dependent variables concerning perceived yield risk were obtained by asking whether the respondent believed that a practice reduces yield risk on a Likert scale. Given limited variation across responses, each question was recoded as a binary variable, with 1 representing \"Agree\" and \"Strongly Agree\" and 0 representing \"Neutral,\" \"Disagree,\" and \"Strongly Disagree.\" Current-use variables are also binary, where 1 indicates the farmer is currently using the practice, and 0 otherwise. Cross-tabulated  statistics for the two binary variables are found in Table 2, which indicates a strong positive relationship between adoption and a belief that the practice reduces yield risk for continuous notill and conservation crop rotations. For those who believe that cover crops reduce yield risk, there is less of a relationship, with similar numbers in both the adopter and nonadopter groups. The VRA statistics are notable, where a majority of farmers who believe VRA reduces yield risk have not adopted. This likely results from financial barriers to VRA adoption. For those farmers who do not believe a practice reduces yield risk, the table shows they largely have not adopted the practice. An exception is conservation crop rotations, where the numbers of adopting and nonadopting farmers are equal. Explanatory variables include a range of binary and continuous variables, defined and summarized in Table 3. The inclusion of these variables is supported by the literature on perceived risk and conservation adoption discussed in the previous section (e.g., Koundouri, Nauges, and Tzouvelekas, 2006;Pannell et al., 2006;Greiner, Patterson, and Miller, 2009). Table 4 presents sample farmer demographics and compares them to the 2012 U.S. Census of Agriculture\n",
      "i=9, j=405, k=408\n",
      "a=census of agriculture\n",
      "g=Census of Agriculture\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=what dataset\n",
      "c=ial patterns vary little over the course of the 2-year LV. Both the total and steric sea level LVs have a strong east-west dipole in the Pacific Ocean, with In particular, the LV shows strong signals in eastern Australia, the Okavango Delta, southeastern United States, and much of South America, among others. This mode is in fact similar in its spatial variability to the decadal trend pattern extracted from much longer records of sea level, precipitation, and TWS in Hamlington et al. (2017) . This Figure 7 . Third CSEOF mode from the combined decomposition representing the decadal (low frequency) variability in each of the three data sets. Seasonally averaged LVs are shown covering the 2-year nested period for altimetry (left), Argo (middle), and GRACE (right). CSEOF = cyclostationary empirical orthogonal function; LV = loading vector; GRACE = Gravity Recovery and Climate Experiment; JFM = January-March; AMJ = April-June; JAS = July-September; OND = October-December. Journal of Geophysical Research: Oceans\n",
      "is further supported by the PCTS (Figure 8a ) that shows a strong negative trend in the first half of the record -again, consistent with Hamlington et al. (2017)-before reversing in the latter half. Indeed, the change in trend seen in the PCTS around 2012 is in agreement with several other studies that identified a possible shift in decadal variability in the Pacific Ocean (e.g., Bromirski et al., 2011) . To further investigate this lowfrequency variability in TWS, a similar mode is extracted through the combined CSEOF analysis of GRACE land water storage and precipitation data from the Global Precipitation Climatology Project (Adler et al., 2003 ) from 2004 to 2016 (Figure 9) . A CSEOF mode is returned with a similar spatial structure and PCTS to the GRACE mode in Figures 7 and 8a . The expression of this low-frequency variability differs in precipitation, however, and relationships between precipitation and TWS become apparent. For example, when this mode is in \n",
      "i=10, j=0, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=National Oceanic and Atmospheric Administration Optimum Interpolation Sea Surface Temperature|Optimum Interpolation Sea Surface Temperature\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=what dataset\n",
      "c=s associated with some frame variable estimates such as gender and demographic group. A portion of the bias present in some estimates may be due to the difference between the nonrespondents and the respondents while other portions of the bias may be due to measurement error (e.g., self-reporting of responses versus administrative reporting of responses) and other sources of nonsampling error. Future investigation should attempt to evaluate the specific source of the S&E degree overestimation, whether it is due to nonresponse bias, measurement error, other nonsampling error or some combination, in an effort to correct this issue for future NSCG survey cycles. A limitation to the degree benchmark analysis is the scope of the comparisons between the 2003 NSCG and IPEDS. The 2003 NSCG target population was U.S. residents holding a U.S. or foreign earned bachelor's degree as of April 1, 2000. However, the comparisons made for this analysis were only for the years 1991 to 1998 and only applied to U.S. earned degrees. Therefore, it is unclear whether the overestimation of S&E degrees might occur in years earlier than 1991. Although the IPEDS survey was mandatory for college institutions receiving federal aid, a nonresponse rate of three to five percent existed for the colleges reporting to the 1991 to 1998 IPEDS. For these nonresponding institutions, imputation was implemented using prior year's data when available or similar institutions data to fill in degree completion information. Though nonresponse was small for IPEDS, the imputation may impact the results of the preceding analysis. Another limitation is the possibility of error in the information provided from the colleges and institutions to IPEDS. To the extent this is true, IPEDS may not live up to its assumed 'gold standard' status. This might imply that the overestimation and underestimation seen in the 2003 NSCG estimates may overstate the quality of NSCG degree estimates.\n",
      "As discussed in the previous sections,\n",
      "i=11, j=0, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=Survey of Doctorate Recipients\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=what dataset\n",
      "c=Intensity standardization in MRI aims at correcting scanner-dependent intensity variations. Existing simple and robust techniques aim at matching the input image histogram onto a standard, while we think that standardization should aim at matching spatially corresponding tissue intensities. In this study, we present a novel automatic technique, called STI for STandardization of Intensities, which not only shares the simplicity and robustness of histogram-matching techniques, but also incorporates tissue spatial intensity information. STI uses joint intensity histograms to determine intensity correspondence in each tissue between the input and standard images. We compared STI to an existing histogram-matching technique on two multicentric datasets, Pilot E-ADNI and ADNI, by measuring the intensity error with respect to the standard image after performing nonlinear registration. The Pilot E-ADNI dataset consisted in 3 subjects each scanned in 7 different sites. The ADNI dataset consisted in 795 subjects scanned in more than 50 different sites. STI was superior to the histogram-matching technique, showing significantly better intensity matching for the brain white matter with respect to the standard image. Magnetic resonance images (MRIs) acquired with similar protocols but on different scanners will show dissimilar intensity values for the same tissue types [1] . These variations are machine-dependent and do not correspond to noise or bias field inhomogeneity, which both can be reduced with different image processing techniques (e.g., [2, 3] , resp.). This problem becomes particularly severe in large, multicentric settings such as the Alzheimer's Disease Neuroimaging Initiative (ADNI), in which longitudinal data is being acquired on more than 50 different platforms in the United States and Canada.\n",
      "Image processing pipelines aimed at extracting tissuebased characteristics (e.g., grey matter/white matter identification) must be robust to these variatio\n",
      "i=12, j=146, k=145\n",
      "a=IMPOSSIBLE\n",
      "g=ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=what dataset\n",
      "c=ADNI [43] , 66 scans.\n",
      " ABIDE [21] , 1287 scans.\n",
      " ADHD [11] , 949 scans.\n",
      " LPBA (LONI Probabilistic Brain Atlas) [51] . This dataset contains 40 scans, each of which comes with segmentation ground truth of 56 anatomical structures.\n",
      "ADNI, ABIDE, ADHD are used for training, and LPBA for testing. All 56 anatomical structures are evaluated by an average Dice score. For atlas-based registration, the first scan in LPBA is fixed as the atlas in our experiments, which 1 Images for training and testing are pre-affined (as required in VoxelMorph [9] ) using ANTs [5] . 2 Reimplemented with an integrated affine network and trained using our method. 3 Denotes one affine registration subnetwork plus three dense deformable subnetworks [37] .\n",
      "is shown to be without loss of generality later in the atlas analysis.\n",
      "We carry out standard preprocessing steps referring to VTN [37] and VoxelMorph [8] . Raw scans are resampled into 128  128  128 voxels after cropping unnecessary area around the target object. For liver CT scans, a simple threshold-based algorithm is applied to find a rough liver bounding box for cropping. For brain MRI scans, skulls are first removed using FreeSurfer [26] . The volumes are visualized for quality control so that seldom badly processed images are manually removed. (An overview of the evaluation datasets is provided in the supplementary material.) Table 1 summarizes our overall performance compared with state-of-the-art methods. Running times are approximately the same across datasets, so we test them on SLIVER, with an NVIDIA TITAN Xp GPU and an Intel Xeon E5-2690 v4 CPU. No GPU implementation of ANTs or Elastix has been found, nor in previous works [5, 8, 19, 35, 37] . As shown in Table 1 , recursive cascaded networks outperform the existing methods in all our datasets with significant gains. More importantly, the proposed architecture is independent of the base network, not limited to VTN [37] and VoxelMorph [8] . Although the number of cascades causes linea\n",
      "i=13, j=1, k=3\n",
      "a=adni\n",
      "g=ADNI\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=what dataset\n",
      "c=ADNI Laboratory of Neuro Imaging (http://adni. loni.usc.edu) site. The MRI scan was spatially normalized to the MNI152 T1 MRI template, and this transformation was then applied to the same participant's tau PET scan. All tau PET images were then transformed into SUVr images using a cerebellar gray matter reference region. Each of the classification schemes was based on binarizing the mean SUVr signals within a predefined set of ROIs and then seeking to match the resulting profile with expected patterns. The three tau PET staging schemes evaluated were as follows:\n",
      "Temporal-Occipital Classification (TOC): This recently published approach [10] was explicitly designed to mimic as closely as possible, in terms of brain regions sampled and decision rules, the Braak 2006 operationalized neuropathologic guidelines [4] . This scheme uses small ROIs localized around the anterior temporal lobe (hippocampus, transentorhinal cortex, fusiform cortex, middle temporal gyrus, and superior temporal gyrus) and in the occipital lobe (extrastriate and primary [striate] visual cortex). Simplified Temporal-Occipital Classification (STOC): This approach was developed as a simplified version of TOC, modified to use fewer and larger ROIs from standard atlases, located in the medial, lateral, and superior temporal lobes and in the primary visual cortex, as well as simpler decision rules. Lobar classification (LC): This approach is simpler than both TOC and STOC and uses whole-lobar average signals from the temporal (T), parietal (P), and frontal (F) lobes. This scheme has the fewest and largest ROIs, sampling most of the cortical gray matter and even simpler decision rules to assign stages.\n",
      "For the TOC scheme only, the tau PET images were gray matter masked for compatibility with the published method [10] . This was achieved by thresholding each individual participant's gray matter tissue probability map at 25% and binarizing to yield an individualized gray matter mask. Gray matter masking wa\n",
      "i=14, j=1, k=3\n",
      "a=adni\n",
      "g=ADNI\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=what dataset\n",
      "c=to role exploration itself. It is still possible a minority of young people may engage in strategic role exploration that is indeed beneficial to their occupational careers. Moreover, the NELS dataset only follows respondents up to age 26. Thus, it is certainly plausible that occupational uncertainty may benefit wage attainments in adulthood. The data simply suggests that if this hypothetical minority exists, it is not best captured by those with uncertain occupational aspirations in adolescence.\n",
      "While we focused on respondents who \"don't know\" their future careers, youth who reported multiple career choices may also be viewed as uncertain. In our sample, approximately 3 percent of women and men at age 16 listed multiple future occupations they aspired to hold at age 30; these women and men who aspired to multiple occupations attained wages that were lower than those who aspired to professional jobs (though these differences were not statistically significant) and were not significantly different from those who responded \"don't know.\" Nevertheless, absent the actual surveys, we were not able to discern the percentage of respondents with multiple occupations aspiring to only professional jobs, or whether the majority aspired to professional and non-professional jobs. The latter category would suggest a greater degree of occupational uncertainty, and future research with more detailed occupational aspiration measures should explore how multiple aspirations affect long-term attainment.\n",
      "Throughout this article, we have made the assumption that youth who indicate they would like to work in a professional or non-professional job in adulthood have \"certain\" occupational aspirations, compared to those youth who \"don't know\" their occupational aspirations. Yet, for at least some of the youth who aspire to professional work in adulthood, this certainty in occupational aspirations may be unrealistic. Research clearly shows that adolescents have increasingly become overly ambit\n",
      "i=15, j=0, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=Education Longitudinal Study|National Education Longitudinal Study\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=what dataset\n",
      "c=ADNI cohort, and identified 11 new susceptibility loci for AD. ADNI also played a prominent role in the largest GWAS of human memory to date including the NIA Health and Retirement Study cohort plus ADNI, the Religious Orders Study and Memory and Aging Project cohort, and other samples (Ramanan et al., in press ). This GWAS implicated the FASTKD2 gene for both episodic memory and hippocampal structure on MRI and nominated this gene as a potential neuroprotective target.\n",
      "Numerous discovery, replication, and methods publications using ADNI genetics data continue to appear from groups around the world at an accelerating pace [131] . Overall, the articles outlined previously along with dozens of other reports using multidimensional phenotypes from several ADNI data sets have confirmed key findings in the genetics of AD and also identified a number of novel candidate genes warranting further investigation in independent cohorts. The proliferation of articles published using ADNI data is undoubtedly a measure of the success of the initiative. However, these studies represent a sometimes overwhelming volume of information to the average researcher. The review of ADNI papers by Weiner et al. [10] and its update [11] summarized this research and enabled researchers to avoid the unnecessary duplication of efforts and to determine where future directions might lie. ADNI has provided a model for neuroimaging initiatives worldwide run under the direction of the umbrella organization, Worldwide ADNI (WW-ADNI), sponsored by the Alzheimer's Association. Programs using ADNI methods have been established in Japan, Australia, Argentina, Taiwan, China, Korea, Europe, and Italy [164] with the common goals of harmonizing protocols and results internationally and sharing standardized data across the international research community. It is hoped that WW-ADNI approaches will establish internationally recognized standards to identify and diagnose AD and document cognitive and physical change\n",
      "i=16, j=1, k=3\n",
      "a=adni\n",
      "g=ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=what dataset\n",
      "c= we showed in Eskildsen et al. (2013) that if cortical thickness is measured in a consistent manner, patterns of cortical thinning can predict conversion to AD among mild cognitive impaired subjects with higher accuracy (68%) compared with conventional voxel-based morphometry (56%) (Davatzikos et al., 2011) and deformation-based morphometry (64%) (Wolz et al., 2011) .\n",
      "In the present study, we combine measurements of structural pathologic patterns, measured by analyzing morphologic alterations, in key structures of the MTL with degenerative patterns of the neocortex, measured by cortical thickness, to determine if prediction accuracies can be improved further by considering the entire gray matter (GM) atrophy footprint of AD. Moreover, we study the advantage of using feature selection to extract the highest relevant information from a set of potential discriminant features.  Data used in the preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (http://adni.loni.usc.edu). The primary goal of ADNI has been to test whether serial MRI, positron emission tomography, other biological markers, and clinical and neuropsychological assessments can be combined to measure the progression of mild cognitive impairment (MCI) and early AD. Determination of sensitive and specific markers of very early AD progression is intended to aid researchers and clinicians to develop new treatments and monitor their effectiveness and lessen the time and cost of clinical trials. ADNI began in 2004 and is ongoing now in its third phase (ADNI2). In this study, we focused on the now completed first phase of ADNI (ADNI1, 2004e2010). For up-to-date information, see http://www.adniinfo.org/.\n",
      "In this study, we selected all 834 ADNI1 subjects available at baseline or screening. Note that only 819 subjects were officially enrolled in ADNI1. However, to compare results with recently published studies on ADNI data (Coupe et al., 2012b; Eskildsen et al., \n",
      "i=17, j=225, k=227\n",
      "a=adni\n",
      "g=ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=what dataset\n",
      "c=heastern Oklahoma. Substitutions to the menu due to access limitations, such as available foods from vendors, spoilage, storage capacity, and food preparation staff needs are permitted (61) . Enrollment at the Head Start programs, which have been in operation the longest of the Osage ECE programs, ranges from 19 to 95 children. The oldest program began operation in 1979, and the most recent program opened in 1985. All 4 WELA programs started more recently, from 2012 to 2017, and the Language Immersion program began in 2015. The WELA and Language Immersion programs served 12-34 children at the time of this study.\n",
      "Menus and meals served to 3-to 5-y-old children were evaluated for each of the 9 programs at the following 5 time points throughout the study: 1) September 2017 (before 2017 CACFP meal pattern requirements were enforced); 2) October-November 2017 (after CACFP meal patterns changed, before food preparers' training on best practices); 3) February-March 2018 (after food preparers' training on best practices, early in FRESH intervention); 4) May 2018 (after food preparers' training on best practices, late in FRESH intervention); and 5) October 2018 (following the FRESH intervention). Only the first 2 time points representing meals immediately before (September 2017) and after (October/November 2017) enforcement of the revised 2017 CACFP meal pattern requirements are presented in this article. All programs operate with a 6-wk-cycle menu. Menus were collected from each program for the 6-wk cycle prior to and after enforcement of the revised 2017 CACFP meal pattern requirement changes, and foods served to children during week 5 were evaluated as described below. Research personnel traveled to each program at least twice, including at least 1 time during the evaluation week to assist with record keeping and recording and again after the evaluation week to collect data for all 5 days. Resources for this level of support for data collection could not be provided throu\n",
      "i=18, j=0, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=Early Childhood Longitudinal Study\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=what dataset\n",
      "c=ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.usc.edu/wpcontent/uploads/how_to_apply/ADNI_Acknowledgeme nt_List.pdf The authors have no conflicts of interest to disclose.    Supplementary Figure 1 . MDS plot of ADNI non-Hispanic Caucasian samples. Samples seemed to form loose clusters and two samples were outliers based on the second MDS component (at bottom of plot; 031_S_4032 and 031_S_4203), suggesting potential population substructure. To check for cryptic relatedness, which can confound GWAS studies, pairwise identity-by-descent fraction () between each pair of samples were calculated using PLINK. Three related sample pairs were identified (137_S_4466 and 021_S_0159,  = 0.50; 023_S_0058 and 023_S_4035,  = 0.48; 024_S_2239 and 024_S_4084,  = 0.42), which are probably first-degree relatives. Optionally, we remove one member of each pair. No other cryptic relations were identified from the sample, at a threshold of  > 0.05.\n",
      "i=19, j=1, k=3\n",
      "a=adni\n",
      "g=ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=what dataset\n",
      "c=total of 30 RA abstracts published from 2011 to 2013 were selected randomly from TESOL Quarterly, a journal with a high impact factor in the field of applied linguistic, to form \"Dataset 1\", representing RA abstracts written by expert writers. And a total of 30 abstracts of theses for Bachelors' degree from 2011 to 2013 in a major Chinese university were collected randomly to form \"Dataset 2\", representing RA abstracts written by student writers. As for the thesis abstracts, in most cases, they are the final step in thesis production and are written without close supervision, hence, it is safe to conclude that they give the most accurate picture of students' academic writing competence. The corpus is approximately 14,400 words in total. For the sake of reliability of the research, the selection of all the abstracts was restricted within three factors. First, the length of the abstracts was controlled between 150-250 words. Second, the topic of the abstracts was narrowed in the discussion of EFL teaching. Thirdly, all the abstracts were selected out of empirical researches. A datasets were analyzed using Santos ' (1996) model. The adoption of this analytical framework is partly due to the practicability of the model owing to the help of the list of questions asked in each move (see Table 1 ), and partially due to the usefulness of the model justified by previous researchers. The basic coding unit for the abstracts was a sentence, which was tagged with a move label. Given the condensed nature of an abstract and the empirical nature of all the researches involved in this study, move-embedding is predictable. Pho (2008) demonstrated that a sentence in an abstract can be responsible for two or more functions simultaneously, thus such a sentence is decoded into two or more moves. Therefore, if move embedding was found in the present study, the sentence would be tagged with two or more move labels. For example, in a sentence \"Using the National Education Longitudinal Study\n",
      "i=20, j=396, k=400\n",
      "a=national education longitudinal study\n",
      "g=Education Longitudinal Study|National Education Longitudinal Study\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=what dataset\n",
      "c=n interpreted using criteria such as in table 1.  Effectiveness-based STM is worksheet to train creative thinking skills of Junior High School students of one class. The test was conducted to find out the effectiveness of the increased value of pre test and post-test, know the value of the average of each of the meetings, as well as an increase in creative thinking skills of students. The average value of pretest and post test each meeting can be seen in table 2. . Based on these results it can be concluded that there is an increase in the average value of each meeting means a meeting 3 average value is greater than 2 meetings and meetings 2 average value is greater than the meeting 1. Increased creative thinking of the students also carried out assessments. The assessment is carried out to find out the increased ability of the creative thinking of each meeting. Increased creative thinking based on charge indicators will in each meeting can be seen in Based on the results of the assessment, it is known that the early creative thinking skills of students still in the category of creative and not creative enough, this shows that creative thinking skills students are still less trained. One factor causes still lack creative thinking of students is the students are still not accustomed to bringing up all kinds of ideas to answer any questions as well as students unfamiliar to do the steps in detail, but After treatment by using the worksheet which have developed creative thinking skills, experience increased entrance requirement i.e., the creative. After treatment by using the taught students worksheet as developed to obtain data through observation activities by using the steps in detail and systematic so that students are able to answer any questions varies, so all the indicators of creative thinking must-have students i.e., think smooth, flexible thinking, original thinking and elaborate experience increased.  Thinking smoothly have been met, judging from the student\n",
      "i=21, j=0, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=Trends in International Mathematics and Science Study\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=what dataset\n",
      "c= 3 to evaluate the contribution of a change in range or the number of states on model performance. If a change in the state's range or number of states performed better, the change remained. Once the node variables were discretized, the graphical model was learned from 80% of the cases of the dataset MRH (n = 180,530). The relative humidity node was set as the target variable, and the machine learning algorithm Tree Augmented Naive Bayes (TAN) was used to learn the model structure ( Figure 3 ). TAN is a Bayesian classifier that incorporates dependencies between attributes by building structures between them [22] . The TAN algorithm drew edges from relative humidity to each proxy variable, and added extra edges between proxy variables. Using the same 80% of the MRH dataset, the Bayesian Counting-Learning Algorithm [18] was used to learn the parameters -prior and conditional probabilities-of all variables in the model. The Counting-Learning Algorithm allows the model to move from initial-ignorance mode to parameterized mode by calculating the conditional probabilities and experience (confidence of the conditional probabilities) of the corresponding combination of variables' states [18, 23] . Once the parameter values are learned, the model can be compiled and is ready for use. 2 A case is the set of values of the proxy variables and relative humidity for a given month and pixel. For example, in the Figure 3B , the case entered in the net has values only for three variables. 3 The Spherical Payoff is a scoring metric used to test the performance of Bayesian network models. The score goes from 0 to 1, where 1 indicates the best performance [51] .  After compiling the model, we did a sensitivity analysis using the variance reduction procedure. The variance reduction estimates the impact of a change in the state of a proxy variable on the state of the target variable [51] . The variance reduction values range from 0 to 100%, where a higher value indicates a higher influen\n",
      "i=22, j=0, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=Agricultural Resource Management Survey\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=what dataset\n",
      "c=ADNI dataset showed that RELM-based classifier could significantly improve accuracy in both binary and multiclass classification tasks. In addition, we could observe that adoption of the PCA-based feature selection could improve the accuracy slightly. While this study is focusing on the stage diagnosis of AD progression using sMRI alone, further study is still being carried out to improve the accuracy by elaborating the classifiers, possibly using a model ensemble approach, and feature selection. Also, the studies of adding more modalities such as fMRI and PET in combination with sMRI are also one of our future researches. The authors declare that there are no competing interests regarding the publication of this paper.\n",
      "i=23, j=1, k=3\n",
      "a=adni\n",
      "g=ADNI\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=what dataset\n",
      "c=hat prostate size would affect BMI or body composition. BPH treatment could have affected biomarker values, however interaction terms were for the most part non-significant, analyses stratified by BPH treatment status did not suggest a consistent pattern or effect, and we control for BPH treatment throughout the main analysis. The blood biomarkers were assayed after several years storage at -80C, which may have decreased precision. It was necessary to measure tissue inflammation in the peripheral zone of the prostate, however the transitional zone may have more direct impact on BPH outcomes. Difuccia and colleagues compared inflammatory cell density across prostate zones, and found peripheral zone inflammatory cell density correlated significantly with inflammatory cell density in transitional zone immune cell density [24] . We measured CD3 and CD20 to provide a score of T and B cell infiltration in prostate tissue, but understand that of other components of immune response may be involved. Tissue inflammation scoring by grade and extent would capture the total inflammatory effect across all immune cell types. We did not adjust for multiple testing, but instead used a traditional significance level of p<0.05 and interpreted results based on our a priori hypothesis. Also, there were several associations that had marginal statistical significance at p<0.10 and, given the imprecision of biomarker analysis, should be considered in future investigations The majority of study participants were white, and results may not generalize to other race/ethnicities. Centralized adipose deposition was associated with the severity of prostate tissue inflammation and LUTS within the subset of participants with prostate tissue inflammation. An approach to minimize centralized fat deposition may reduce LUTS severity in BPH patients. Lack of a clear relationship between blood or urinary biomarkers of inflammation or oxidative stress with prostate size or LUTS suggests the effects of obe\n",
      "i=24, j=0, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=Baltimore Longitudinal Study of Aging\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=what dataset\n",
      "c= al., 2003, Rampen et al., 2007. Interestingly, the C 32 1,15 diol scores opposite to the C 30 1,15-diol on PC1, suggesting a different behavior compared to the C 30 1,15 diol. This is even more evident for the PCA of LCD distribution of the riverine SPM where the C 32 1,15-diol loads opposite all other diols on PC1. This suggests that the C 32 1,15-diol does not have the same source and/or environmental controls as the other diols. To further investigate the controls on the fractional abundance of the C 32 1,15-diol, we investigated the relationships between the fractional abundance of the C 32 1,15-diol, annual mean SST, TOC,  13 C of bulk OM ( 13 C OM ), BIT index and distance to the river mouth. The  13 C OM is a proxy for bulk terrigenous versus marine OM (Meyers, 1994) and the BIT index is a proxy for input from continental (riverine and soil) OM into the marine realm (Hopmans et al., 2004;Walsh et al., 2008;Zell et al., 2014 andDe Jonge et al., 2015). For this comparison we excluded the 1,14-diols from the data set as the 1,14 diols are known to be produced by another group of organisms (Proboscia diatoms; Sinninghe Damste et al., 2003;Rampen et al., 2007)  The results for the combined dataset show no relationship between the percentage of C 32 1,15-diol and SST (r = 0.001, p value=0.99; Table 1) agreeing with the conclusion of Rampen et al. (2012). To the contrary, there is a significant positive correlation between C 32 1,15-diol and BIT index (r=0.3, p<0.005, Table 1) and a significant negative correlation with  13 C OM (r=-0.6, p<0.005, Table 1). On a regional level, the correlation between C 32 1,15-diol and BIT index is also observed in the Gulf of Lion and t\n",
      "i=25, j=0, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=World Ocean Database\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=what dataset\n",
      "c=range from 66.3 to 86.6 degree. In crossing fiber regions of Figure 4 (Top), the more transparent the tensor is, the less weight it takes.\n",
      "In addition, S 0 (s)'s have the same value which is set to 1000. Two choices of the noise standard deviation  are used, namely 50 and 100, which corresponds to signal-to-noise ratio (S 0 /) of 20 and 10, respectively. The case that SNR = 20 is typical for dMRI studies while that SNR = 10 corresponds to a high noise setting. The set of gradient directions U is obtained from the sphere tessellation with 3 subdivision using octahedron and |U| = 33, which is in a typical range for dMRI studies nowadays. With these gradient directions, the observed signal intensities S(s)'s are simulated according to the multi-tensor model (2) with the Rician noise. A total of four different procedures are compared:\n",
      " raw: voxel-wise estimation without any smoothing;\n",
      " DiST-cv: DiST using ordinary cross-validation score for choosing h;\n",
      " DiST-tcv: DiST using 5% trimmed cross-validation score for choosing h;\n",
      " DiST-mcv: DiST using median cross-validation score for choosing h.\n",
      "See Section S3 of the SM for definitions of the various cross-validation variants. \n",
      "whereu 1 , . . . ,u J are the estimated diffusion directions. Here, the MSE is the mean of squared errors (10) over voxels withJ = J in one simulated data set and root MSE (RMSE) is the square root of MSE. Then MMSE and MRMSE are defined, respectively, as the means of MSEs and\n",
      "RMSEs over the 200 simulated data sets.\n",
      "The voxel-wise estimation works reasonably well in estimating both the number of diffusion directions J and the diffusion directions. Even for the low SNR setting, the correctness of estimation of J is around 75% and the angular error is no more than 11 degree. For the single tensor region (J = 1), smoothing improves upon estimation of both J and diffusion directions. For regions with two tensors (J = 2), smoothing only improves direction estimation. Among the three smoothing procedures, Di\n",
      "i=26, j=0, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=what dataset\n",
      "c=udents may avoid these fields, anticipating that wages will go down when the fields are \"too female.\" Bellas (1992) shows that academic salaries are lower in fields with a higher proportion of female faculty, especially when the proportion goes beyond a certain point. Furthermore, male students may find it socially stigmatizing to pursue fields of study with a preponderance of females (England et al., 2004). If this trend continues, segregation among academic fields is likely to occur, and a stable, integrated gender equilibrium will be at stake. Somewhat surprisingly, very few studies have addressed whether more foreign doctorates have led to fewer native doctorates and why certain academic fields are becoming predominantly female. 5 Moreover, when examined at all, these two issues are often addressed separately. This study looks at these issues in a connected way by linking findings from both areas, thus enabling us to have a more complete picture of the changing pattern of doctorate production in American universities. In particular, I ask two questions: (1) Is there a crowding-out effect of foreign doctorates on native doctorates? If so, in what fields, and is there a difference by gender? (2) Do male students exhibit \"women-avoiding\" behaviors in pursuing doctoral studies? If so, in what fields, and is there a difference by citizenship? The organization of this paper is as follows. In Section Two, I discuss two possible models to explain the trend of doctorate production in American universities during the last four decades or so. Several hypotheses are generated from these models. After describing data and estimation strategies in Section Three, in Section Four I estimate panel data models to examine the crowding-out effect and the \"women-avoiding\" behaviors. The final section concludes and provides some policy discussion. The crowding-out effect is a term used loosely by researchers to attribute the shrinkage of one group to the growth of others. For example,\n",
      "i=27, j=0, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=Survey of Earned Doctorates\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=what dataset\n",
      "c=e related-learning-domains.\n",
      "In particular, we develop a novel multi-domain transfer learning (MDTL) method for early diagnosis of AD, where training data from multiple auxiliary domains are jointly learned with the target domain. Specifically, we first develop a multidomain transfer feature selection (MDTFS) model by using the training data from multiple auxiliary domains and target domain to select a subset of discriminative features. Then, we build a multi-domain transfer classifier (MDTC) that can conjointly apply the training data from multi-auxiliary domains and target domain to construct the classifier. The proposed method is evaluated on the baseline Alzheimer's Disease Neuroimaging Initiative (ADNI) database of 807 subjects with MRI data. The experimental results demonstrate that the proposed method can further improve the performance of early diagnosis of AD, compared with several state-of-the-art methods.  The data used in the preparation of this paper were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (http://adni.loni.usc.edu/). ADNI researchers collect, validate and utilize data such as MRI and positron emission tomography (PET) images, genetics, cognitive tests, cerebrospinal fluid (CSF) and blood biomarkers as predictors for Alzheimer's disease. Data from the North American ADNI's study participants, including Alzheimer's disease patients, mild cognitive impairment subjects and elderly controls, are available in this database. In addition, the ADNI was launched in 2003 by the National Institute on Aging (NIA), the National Institute of Biomedical Imaging and Bioengineering (NIBIB), the Food and Drug Administration (FDA), private pharmaceutical companies, and non-profit organizations, as a $60 million, 5-year public-private partnership. The primary goal of ADNI has been to test whether the serial MRI, PET, other biological markers, and clinical and neuropsychological assessments can be combined to measure the progression of MCI and early AD. Determination of sensitive a\n",
      "i=28, j=144, k=146\n",
      "a=adni\n",
      "g=ADNI|Alzheimer's Disease Neuroimaging Initiative (ADNI)\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=what dataset\n",
      "c= West, intensifying in the 1900s after improvements in irrigation and fertilizers (Hurt, 2002) .\n",
      "Increasing agricultural land cover facilitated range expansions of many insects, and some emerged as serious pests (Kim & Sappington, 2005) . One such pest, Colorado potato beetle (Leptinotarsa decemlineata Say), a specialist leaf beetle of plants in the family Solanaceae, arose when the staple crop of European American pioneers, the potato (Solanum tuberosum L.), reached the Great Plains (Casagrande, 1985; Walsh, 1866) . In the United States, the history of L. decemlineata range expansion is well documented; the first shift from its ancestral host plant, buffalo bur (Solanum rostratum Dunal), to potato was reported in 1859 in central Nebraska (Riley, 1869; Walsh, 1866) , and most major potato-producing regions were subsequently colonized by 1910 (Hsiao, 1985; Tower, 1906) . Despite an initially rapid transcontinental invasion, L. decemlineata is not a highly dispersive species, being predominantly sessile as larvae, and preferring walking over flight as adults (Boiteau, Alyokhin, & Ferro, 2003; Hare, 1990) . A relatively long residence time and low migration rate in agricultural landscapes make L. decemlineata a good model to examine how legacies of historical agricultural land cover have shaped contemporary genetic differentiation in insect pest populations. We set out to test whether agricultural production, and how it has changed across time, influences the genetic diversity and genetic structure of the Colorado potato beetle.\n",
      "One important challenge to detecting landscape effects on genetic differentiation is the potentially confounding effects of populations' underlying demographic history (Schoville, Lam, & Roderick, 2012) . Here, we compared two widely separated landscapes, to examine whether demographic history is a factor influencing observed population genetic structure and variation. We estimated the effects of historical changes in potato land cover on L. de\n",
      "i=29, j=0, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=Census of Agriculture\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(contexts, questions, truncation=\"only_first\", padding=\"max_length\", return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "start_logits, end_logits = model(**inputs).values()\n",
    "for i in range(len(start_logits)):    \n",
    "    j = torch.argmax(start_logits[i])  \n",
    "    k = torch.argmax(end_logits[i]) + 1\n",
    "    a = \"IMPOSSIBLE\"\n",
    "    if 0 < j < k:\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids[i][j:k])\n",
    "        a = tokenizer.convert_tokens_to_string(tokens)\n",
    "    print(f\"\\n\\nis_impossible={is_impossible[i]}\\nq={questions[i]}\\nc={contexts[i]}\\ni={i}, j={j}, k={k}\\na={a}\\ng={golds[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87ce32f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
