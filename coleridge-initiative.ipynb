{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worst-module",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-22T09:53:30.691395Z",
     "iopub.status.busy": "2021-06-22T09:53:30.690759Z",
     "iopub.status.idle": "2021-06-22T09:53:32.736100Z",
     "shell.execute_reply": "2021-06-22T09:53:32.735454Z",
     "shell.execute_reply.started": "2021-06-22T09:52:15.442407Z"
    },
    "papermill": {
     "duration": 2.067352,
     "end_time": "2021-06-22T09:53:32.736254",
     "exception": false,
     "start_time": "2021-06-22T09:53:30.668902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import configparser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spiritual-brazilian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:53:32.771948Z",
     "iopub.status.busy": "2021-06-22T09:53:32.771296Z",
     "iopub.status.idle": "2021-06-22T09:53:32.777714Z",
     "shell.execute_reply": "2021-06-22T09:53:32.777211Z",
     "shell.execute_reply.started": "2021-06-22T09:52:15.452459Z"
    },
    "papermill": {
     "duration": 0.027702,
     "end_time": "2021-06-22T09:53:32.777821",
     "exception": false,
     "start_time": "2021-06-22T09:53:32.750119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "seed = 31\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dangerous-disability",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:53:32.800957Z",
     "iopub.status.busy": "2021-06-22T09:53:32.800488Z",
     "iopub.status.idle": "2021-06-22T09:53:40.341676Z",
     "shell.execute_reply": "2021-06-22T09:53:40.341247Z",
     "shell.execute_reply.started": "2021-06-22T09:52:15.468801Z"
    },
    "papermill": {
     "duration": 7.554769,
     "end_time": "2021-06-22T09:53:40.341787",
     "exception": false,
     "start_time": "2021-06-22T09:53:32.787018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "INPUT = '/kaggle/input'\n",
    "DATA = f'{INPUT}/coleridgeinitiative-show-us-the-data'\n",
    "TEMP = '/kaggle/temp'\n",
    "OUTPUT = '/kaggle/working'\n",
    "RESOURCE_DIR = f'{INPUT}/coleridge-initiative-lib/kaggle-coleridge-initiative-1.0'\n",
    "#TOK_DIR = f\"{RESOURCE_DIR}/pretrained/google/electra-small-discriminator\"\n",
    "MODEL_DIR = f\"{RESOURCE_DIR}/models/electra_small/20210621_1800\"\n",
    "sys.path.append(f'{INPUT}/sgcharts-ml/src')\n",
    "sys.path.append(f'{RESOURCE_DIR}/src')\n",
    "import mylib\n",
    "import scml\n",
    "from scml import nlp as snlp\n",
    "scml.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "overall-charles",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:53:40.364100Z",
     "iopub.status.busy": "2021-06-22T09:53:40.363261Z",
     "iopub.status.idle": "2021-06-22T09:53:40.456300Z",
     "shell.execute_reply": "2021-06-22T09:53:40.455806Z",
     "shell.execute_reply.started": "2021-06-22T09:52:15.482209Z"
    },
    "papermill": {
     "duration": 0.105834,
     "end_time": "2021-06-22T09:53:40.456470",
     "exception": false,
     "start_time": "2021-06-22T09:53:40.350636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='/kaggle/input/coleridge-initiative-lib/kaggle-coleridge-initiative-1.0/models/electra_small/20210621_1800', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "model_max_length = 512\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, model_max_length=model_max_length)\n",
    "print(f\"{repr(tokenizer)}\\n{tokenizer.model_input_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "perfect-reasoning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:53:40.480546Z",
     "iopub.status.busy": "2021-06-22T09:53:40.479947Z",
     "iopub.status.idle": "2021-06-22T09:53:42.577149Z",
     "shell.execute_reply": "2021-06-22T09:53:42.576467Z",
     "shell.execute_reply.started": "2021-06-22T09:52:15.563436Z"
    },
    "papermill": {
     "duration": 2.109977,
     "end_time": "2021-06-22T09:53:42.577303",
     "exception": false,
     "start_time": "2021-06-22T09:53:40.467326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraConfig {\n",
      "  \"_name_or_path\": \"/kaggle/input/coleridge-initiative-lib/kaggle-coleridge-initiative-1.0/models/electra_small/20210621_1800\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.5.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_DIR)\n",
    "print(repr(model.config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "raised-practitioner",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:53:42.610590Z",
     "iopub.status.busy": "2021-06-22T09:53:42.609905Z",
     "iopub.status.idle": "2021-06-22T09:53:42.642296Z",
     "shell.execute_reply": "2021-06-22T09:53:42.642801Z",
     "shell.execute_reply.started": "2021-06-22T09:52:16.061218Z"
    },
    "papermill": {
     "duration": 0.050915,
     "end_time": "2021-06-22T09:53:42.642959",
     "exception": false,
     "start_time": "2021-06-22T09:53:42.592044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Id                4 non-null      object\n",
      " 1   PredictionString  4 non-null      object\n",
      "dtypes: object(2)\n",
      "memory usage: 192.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv(f\"{DATA}/sample_submission.csv\", engine=\"c\", low_memory=False)\n",
    "sub[\"PredictionString\"] = sub[\"PredictionString\"].astype(str)\n",
    "sub.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "utility-resident",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:53:42.681410Z",
     "iopub.status.busy": "2021-06-22T09:53:42.679738Z",
     "iopub.status.idle": "2021-06-22T09:53:42.682938Z",
     "shell.execute_reply": "2021-06-22T09:53:42.683402Z",
     "shell.execute_reply.started": "2021-06-22T09:52:16.081489Z"
    },
    "papermill": {
     "duration": 0.026088,
     "end_time": "2021-06-22T09:53:42.683533",
     "exception": false,
     "start_time": "2021-06-22T09:53:42.657445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def qa_predict(\n",
    "    data_dir: str,\n",
    "    model: AutoModelForQuestionAnswering,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    question: str,\n",
    "    window_length: int,\n",
    "    window_stride: int,\n",
    "    max_windows: int,\n",
    "    verbose: bool = False,\n",
    ") -> Callable:\n",
    "    def fn(row) -> str:\n",
    "        rid = row[\"Id\"]\n",
    "        tmp = []\n",
    "        with open(f\"{data_dir}/{rid}.json\") as in_file:\n",
    "            sections = json.load(in_file)\n",
    "        for section in sections:\n",
    "            tmp.append(section[\"text\"])\n",
    "        text = \" \".join(tmp).strip()\n",
    "        text = snlp.to_ascii_str(text)\n",
    "        i = 0\n",
    "        j = i + window_length\n",
    "        k = 0\n",
    "        contexts = []\n",
    "        while k < max_windows and len(text) - i >= window_stride:\n",
    "            if verbose:\n",
    "                print(f\"i={i}, j={j}, k={k}\")\n",
    "            context = text[i:j]\n",
    "            contexts.append(context)\n",
    "            i += window_stride\n",
    "            j = i + window_length\n",
    "            k += 1\n",
    "        questions = [question] * len(contexts)\n",
    "        inputs = tokenizer(contexts, questions, truncation=\"only_first\", padding=\"max_length\", return_tensors=\"pt\")\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        start_logits, end_logits = model(**inputs).values()\n",
    "        if verbose:\n",
    "            print(f\"start_logits.size={start_logits.size()}, end_logits.size={end_logits.size()}\")\n",
    "        res = set()\n",
    "        for k in range(len(start_logits)):\n",
    "            i = torch.argmax(start_logits[k])  \n",
    "            j = torch.argmax(end_logits[k]) + 1\n",
    "            if 0 < i < j:\n",
    "                tokens = tokenizer.convert_ids_to_tokens(input_ids[k][i:j])\n",
    "                a = tokenizer.convert_tokens_to_string(tokens)\n",
    "                a = mylib.clean_text(a)\n",
    "                if verbose:\n",
    "                    print(f\"k={k}, i={i}, j={j}, a={a}, tokens={tokens}\")\n",
    "                # TODO if special token is present, discard answer (possibly truncated)\n",
    "                res.add(a)\n",
    "        return \"|\".join(res)\n",
    "\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-college",
   "metadata": {
    "papermill": {
     "duration": 0.009411,
     "end_time": "2021-06-22T09:53:42.702662",
     "exception": false,
     "start_time": "2021-06-22T09:53:42.693251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "weekly-saskatchewan",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:53:42.724194Z",
     "iopub.status.busy": "2021-06-22T09:53:42.723745Z",
     "iopub.status.idle": "2021-06-22T09:54:26.755559Z",
     "shell.execute_reply": "2021-06-22T09:54:26.755949Z",
     "shell.execute_reply.started": "2021-06-22T09:52:16.097863Z"
    },
    "papermill": {
     "duration": 44.043585,
     "end_time": "2021-06-22T09:54:26.756075",
     "exception": false,
     "start_time": "2021-06-22T09:53:42.712490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 8.41 s, total: 1min 25s\n",
      "Wall time: 44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sub[\"PredictionString\"] = sub.apply(\n",
    "    qa_predict(\n",
    "        data_dir=f\"{DATA}/test\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        question=\"what dataset\",\n",
    "        window_length=2000,\n",
    "        window_stride=1500,\n",
    "        max_windows=30,\n",
    "        verbose=False,\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "confident-flavor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:54:26.783551Z",
     "iopub.status.busy": "2021-06-22T09:54:26.782863Z",
     "iopub.status.idle": "2021-06-22T09:54:26.794984Z",
     "shell.execute_reply": "2021-06-22T09:54:26.794458Z",
     "shell.execute_reply.started": "2021-06-22T09:52:31.976152Z"
    },
    "papermill": {
     "duration": 0.028938,
     "end_time": "2021-06-22T09:54:26.795119",
     "exception": false,
     "start_time": "2021-06-22T09:54:26.766181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2100032a-7c33-4bff-97ef-690822c43466</td>\n",
       "      <td>adni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f392438-e215-4169-bebf-21ac4ff253e1</td>\n",
       "      <td>trends in international mathematics and science study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3f316b38-1a24-45a9-8d8c-4e05a42257c6</td>\n",
       "      <td>slosh model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60</td>\n",
       "      <td>rural urban continuum codes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  \\\n",
       "0  2100032a-7c33-4bff-97ef-690822c43466   \n",
       "1  2f392438-e215-4169-bebf-21ac4ff253e1   \n",
       "2  3f316b38-1a24-45a9-8d8c-4e05a42257c6   \n",
       "3  8e6996b4-ca08-4c0b-bed2-aaf07a4c6a60   \n",
       "\n",
       "                                        PredictionString  \n",
       "0                                                   adni  \n",
       "1  trends in international mathematics and science study  \n",
       "2                                            slosh model  \n",
       "3                            rural urban continuum codes  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "novel-biography",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:54:26.829982Z",
     "iopub.status.busy": "2021-06-22T09:54:26.829530Z",
     "iopub.status.idle": "2021-06-22T09:54:26.835277Z",
     "shell.execute_reply": "2021-06-22T09:54:26.834923Z",
     "shell.execute_reply.started": "2021-06-22T09:52:31.988108Z"
    },
    "papermill": {
     "duration": 0.024731,
     "end_time": "2021-06-22T09:54:26.835394",
     "exception": false,
     "start_time": "2021-06-22T09:54:26.810663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-tension",
   "metadata": {
    "papermill": {
     "duration": 0.010141,
     "end_time": "2021-06-22T09:54:26.856062",
     "exception": false,
     "start_time": "2021-06-22T09:54:26.845921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aquatic-robinson",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:54:26.880676Z",
     "iopub.status.busy": "2021-06-22T09:54:26.880178Z",
     "iopub.status.idle": "2021-06-22T09:54:26.883100Z",
     "shell.execute_reply": "2021-06-22T09:54:26.883513Z",
     "shell.execute_reply.started": "2021-06-22T09:52:32.004148Z"
    },
    "papermill": {
     "duration": 0.017172,
     "end_time": "2021-06-22T09:54:26.883657",
     "exception": false,
     "start_time": "2021-06-22T09:54:26.866485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 65.811209,
   "end_time": "2021-06-22T09:54:29.559531",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-22T09:53:23.748322",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
