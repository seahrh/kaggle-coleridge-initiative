{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb5c65db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import scml\n",
    "from scml import nlp as snlp\n",
    "import mylib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4949320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01f7287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.36 s, sys: 2.44 s, total: 5.8 s\n",
      "Wall time: 5.83 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('pretrained/spacy/en_core_web_lg/en_core_web_lg-2.3.1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nlp = spacy.load(\"pretrained/spacy/en_core_web_lg/en_core_web_lg-2.3.1\")\n",
    "nlp.max_length = 1_000_000\n",
    "nlp.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a7e5504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "Some weights of BertForQuestionAnswering were not initialized from the TF 2.0 model and are newly initialized: ['bert.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"pretrained/bert-large-uncased-whole-word-masking-finetuned-squad\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.5.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "CPU times: user 15.2 s, sys: 9.14 s, total: 24.4 s\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"pretrained/bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    \"pretrained/bert-large-uncased-whole-word-masking-finetuned-squad\",\n",
    "    from_tf=True,\n",
    ")\n",
    "print(repr(model.config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b59059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14316 entries, 0 to 14315\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Id            14316 non-null  object\n",
      " 1   ground_truth  14316 non-null  object\n",
      " 2   is_multi      14316 non-null  int8  \n",
      "dtypes: int8(1), object(2)\n",
      "memory usage: 237.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet(\"input/train.parquet\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378fb17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_predict(data_dir, nlp, model, tokenizer, question, stride, window_length, n_window=None):\n",
    "    def fn(row) -> str:\n",
    "        rid = row[\"Id\"]\n",
    "        tmp = []\n",
    "        with open(f\"{data_dir}/{rid}.json\") as in_file:\n",
    "            sections = json.load(in_file)\n",
    "            for section in sections:\n",
    "                tmp.append(section[\"text\"])\n",
    "        text = \" \".join(tmp).strip()\n",
    "        if len(text) > nlp.max_length:\n",
    "            text = text[:nlp.max_length]\n",
    "        doc = nlp(text)\n",
    "        sentences = [sent.string.strip() for sent in doc.sents]\n",
    "        if n_window is not None:\n",
    "            sentences = sentences[:window_length * n_window]\n",
    "        res = set()\n",
    "        for i in range(0, len(sentences), stride):\n",
    "            tmp = sentences[i:i + window_length]\n",
    "            #print(f\"i={i}, len(tmp)={len(tmp)}\")\n",
    "            passage = \" \".join(tmp)\n",
    "            inputs = tokenizer.encode_plus(\n",
    "                question, passage,\n",
    "                truncation=\"only_second\",\n",
    "                max_length=512,\n",
    "                add_special_tokens=True, \n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "            sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "            answer_start_scores, answer_end_scores = model(**inputs).values()\n",
    "            #print(f\"answer_start_scores.shape={answer_start_scores.shape}, answer_end_scores.shape={answer_end_scores.shape}\")\n",
    "            ai = torch.argmax(answer_start_scores)\n",
    "            aj = torch.argmax(answer_end_scores) + 1\n",
    "            #print(f\"ai={ai}, aj={aj}\")\n",
    "            if ai <= sep_index:\n",
    "                continue\n",
    "            a = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[ai:aj]))\n",
    "            a = mylib.clean_text(a)\n",
    "            if len(a) < 4 or len(a) > 150:\n",
    "                continue\n",
    "            n_digits = snlp.count_digit(a)\n",
    "            if n_digits > 4 or n_digits / len(a) > 0.2:\n",
    "                continue\n",
    "            res.add(a)\n",
    "        return \"|\".join(res)\n",
    "    \n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8daf1a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14316/14316 [3:55:37<00:00,  1.01it/s]   \n"
     ]
    }
   ],
   "source": [
    "train[\"PredictionString\"] = train.progress_apply(\n",
    "    qa_predict(\n",
    "        data_dir=f\"input/train\",\n",
    "        nlp=nlp,\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        question=\"name dataset\",\n",
    "        window_length=4,\n",
    "        stride=4,\n",
    "        n_window=1,\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed8c72f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14316 entries, 0 to 14315\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Id                14316 non-null  object\n",
      " 1   ground_truth      14316 non-null  object\n",
      " 2   is_multi          14316 non-null  int8  \n",
      " 3   PredictionString  14316 non-null  object\n",
      "dtypes: int8(1), object(3)\n",
      "memory usage: 349.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe982ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>is_multi</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d0fa7568-7d8e-4db9-870f-f9c6f668c17b</td>\n",
       "      <td>education longitudinal study|national education longitudinal study</td>\n",
       "      <td>1</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f26f645-3dec-485d-b68d-f013c9e05e60</td>\n",
       "      <td>education longitudinal study|national education longitudinal study</td>\n",
       "      <td>1</td>\n",
       "      <td>national education longitudinal study of 1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c5d5cd2c-59de-4f29-bbb1-6a88c7b52f29</td>\n",
       "      <td>education longitudinal study|national education longitudinal study</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5c9a3bc9-41ba-4574-ad71-e25c1442c8af</td>\n",
       "      <td>education longitudinal study|national education longitudinal study</td>\n",
       "      <td>1</td>\n",
       "      <td>federal reserve bank of richmond s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c754dec7-c5a3-4337-9892-c02158475064</td>\n",
       "      <td>education longitudinal study|national education longitudinal study</td>\n",
       "      <td>1</td>\n",
       "      <td>national education longitudinal study nels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  \\\n",
       "0  d0fa7568-7d8e-4db9-870f-f9c6f668c17b   \n",
       "1  2f26f645-3dec-485d-b68d-f013c9e05e60   \n",
       "2  c5d5cd2c-59de-4f29-bbb1-6a88c7b52f29   \n",
       "3  5c9a3bc9-41ba-4574-ad71-e25c1442c8af   \n",
       "4  c754dec7-c5a3-4337-9892-c02158475064   \n",
       "\n",
       "                                                         ground_truth  \\\n",
       "0  education longitudinal study|national education longitudinal study   \n",
       "1  education longitudinal study|national education longitudinal study   \n",
       "2  education longitudinal study|national education longitudinal study   \n",
       "3  education longitudinal study|national education longitudinal study   \n",
       "4  education longitudinal study|national education longitudinal study   \n",
       "\n",
       "   is_multi                               PredictionString  \n",
       "0         1          national education longitudinal study  \n",
       "1         1  national education longitudinal study of 1988  \n",
       "2         1                                                 \n",
       "3         1            federal reserve bank of richmond s1  \n",
       "4         1    national education longitudinal study nels   "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a5ca072",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet(\"output/validation.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd1de410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score=0.0572\n",
      "CPU times: user 125 ms, sys: 156 ms, total: 281 ms\n",
      "Wall time: 183 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = mylib.fbeta(y_true=train[\"ground_truth\"], y_pred=train[\"PredictionString\"])\n",
    "print(f\"score={score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ebad0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"|\".join([]) == \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef51dc98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
