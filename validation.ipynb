{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bb5c65db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import scml\n",
    "from scml import nlp as snlp\n",
    "import mylib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4949320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "scml.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b01f7287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.14 s, sys: 500 ms, total: 4.64 s\n",
      "Wall time: 4.66 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('pretrained/spacy/en_core_web_lg/en_core_web_lg-2.3.1')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nlp = spacy.load(\"pretrained/spacy/en_core_web_lg/en_core_web_lg-2.3.1\")\n",
    "nlp.max_length = 1_000_000\n",
    "nlp.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1a7e5504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "Some weights of BertForQuestionAnswering were not initialized from the TF 2.0 model and are newly initialized: ['bert.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"pretrained/bert-large-uncased-whole-word-masking-finetuned-squad\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.5.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "CPU times: user 16 s, sys: 797 ms, total: 16.8 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"pretrained/bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    \"pretrained/bert-large-uncased-whole-word-masking-finetuned-squad\",\n",
    "    from_tf=True,\n",
    ")\n",
    "print(repr(model.config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "24b59059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 6004 to 6979\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Id            1000 non-null   object\n",
      " 1   ground_truth  1000 non-null   object\n",
      " 2   is_multi      1000 non-null   int8  \n",
      "dtypes: int8(1), object(2)\n",
      "memory usage: 24.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet(\"input/train.parquet\")\n",
    "train = train.sample(1000)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "378fb17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_predict(data_dir, nlp, model, tokenizer, question, stride, window_length, n_window=None):\n",
    "    def fn(row) -> str:\n",
    "        rid = row[\"Id\"]\n",
    "        tmp = []\n",
    "        with open(f\"{data_dir}/{rid}.json\") as in_file:\n",
    "            sections = json.load(in_file)\n",
    "            for section in sections:\n",
    "                tmp.append(section[\"text\"])\n",
    "        text = \" \".join(tmp).strip()\n",
    "        if len(text) > nlp.max_length:\n",
    "            text = text[:nlp.max_length]\n",
    "        doc = nlp(text)\n",
    "        sentences = [sent.string.strip() for sent in doc.sents]\n",
    "        if n_window is not None:\n",
    "            sentences = sentences[:window_length * n_window]\n",
    "        res = set()\n",
    "        for i in range(0, len(sentences), stride):\n",
    "            tmp = sentences[i:i + window_length]\n",
    "            #print(f\"i={i}, len(tmp)={len(tmp)}\")\n",
    "            passage = \" \".join(tmp)\n",
    "            inputs = tokenizer.encode_plus(\n",
    "                question, passage,\n",
    "                truncation=\"only_second\",\n",
    "                max_length=512,\n",
    "                add_special_tokens=True, \n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "            sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "            answer_start_scores, answer_end_scores = model(**inputs).values()\n",
    "            #print(f\"answer_start_scores.shape={answer_start_scores.shape}, answer_end_scores.shape={answer_end_scores.shape}\")\n",
    "            ai = torch.argmax(answer_start_scores)\n",
    "            aj = torch.argmax(answer_end_scores) + 1\n",
    "            #print(f\"ai={ai}, aj={aj}\")\n",
    "            if ai <= sep_index:\n",
    "                continue\n",
    "            a = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[ai:aj]))\n",
    "            a = mylib.clean_text(a)\n",
    "            if len(a) < 4 or len(a) > 150:\n",
    "                continue\n",
    "            n_digits = snlp.count_digit(a)\n",
    "            if n_digits > 4 or n_digits / len(a) > 0.2:\n",
    "                continue\n",
    "            res.add(a)\n",
    "        return \"|\".join(res)\n",
    "    \n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8daf1a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:06:43<00:00,  4.00s/it]\n"
     ]
    }
   ],
   "source": [
    "train[\"PredictionString\"] = train.progress_apply(\n",
    "    qa_predict(\n",
    "        data_dir=f\"input/train\",\n",
    "        nlp=nlp,\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        question=\"name of dataset database study survey program initiative model assessment archive collection catalog registry\",\n",
    "        window_length=4,\n",
    "        stride=3,\n",
    "        n_window=6,\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ed8c72f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 6004 to 6979\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Id                1000 non-null   object\n",
      " 1   ground_truth      1000 non-null   object\n",
      " 2   is_multi          1000 non-null   int8  \n",
      " 3   PredictionString  1000 non-null   object\n",
      "dtypes: int8(1), object(3)\n",
      "memory usage: 32.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fe982ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>is_multi</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6004</th>\n",
       "      <td>97701c3c-520a-4608-bd8c-8aa0b520b2b4</td>\n",
       "      <td>adni</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11427</th>\n",
       "      <td>3d0a9255-ed82-463e-9502-0721db008ccf</td>\n",
       "      <td>rural urban continuum codes</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>d26c90cd-a108-4613-bd30-6b22aeba1dc9</td>\n",
       "      <td>coastal change analysis program</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292</th>\n",
       "      <td>64488cc2-7515-4385-a3b7-64c50767d526</td>\n",
       "      <td>adni|alzheimer s disease neuroimaging initiative adni</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4670</th>\n",
       "      <td>50e5ce99-d967-417f-b343-b30c2f8529c5</td>\n",
       "      <td>adni|alzheimer s disease neuroimaging initiative adni</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Id  \\\n",
       "6004   97701c3c-520a-4608-bd8c-8aa0b520b2b4   \n",
       "11427  3d0a9255-ed82-463e-9502-0721db008ccf   \n",
       "8064   d26c90cd-a108-4613-bd30-6b22aeba1dc9   \n",
       "4292   64488cc2-7515-4385-a3b7-64c50767d526   \n",
       "4670   50e5ce99-d967-417f-b343-b30c2f8529c5   \n",
       "\n",
       "                                                 ground_truth  is_multi  \\\n",
       "6004                                                     adni         0   \n",
       "11427                             rural urban continuum codes         0   \n",
       "8064                          coastal change analysis program         0   \n",
       "4292   adni|alzheimer s disease neuroimaging initiative adni          1   \n",
       "4670   adni|alzheimer s disease neuroimaging initiative adni          1   \n",
       "\n",
       "      PredictionString  \n",
       "6004                    \n",
       "11427                   \n",
       "8064                    \n",
       "4292                    \n",
       "4670                    "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9a5ca072",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet(\"output/validation.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cd1de410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score=0.0946\n",
      "CPU times: user 15.6 ms, sys: 15.6 ms, total: 31.2 ms\n",
      "Wall time: 14.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = mylib.fbeta(y_true=train[\"ground_truth\"], y_pred=train[\"PredictionString\"])\n",
    "print(f\"score={score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7ebad0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1746\n",
    "# question=\"name dataset study survey program initiative\",\n",
    "# window_length=4,\n",
    "# stride=3,\n",
    "# n_window=6,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ef51dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"|\".join([]) == \"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
