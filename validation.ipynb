{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb5c65db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from typing import Deque\n",
    "import scml\n",
    "from scml import nlp as snlp\n",
    "import mylib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4949320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "scml.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b01f7287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#nlp = spacy.load(\"pretrained/spacy/en_core_web_lg/en_core_web_lg-2.3.1\")\n",
    "#nlp.max_length = 1_000_000\n",
    "#nlp.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a7e5504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing DistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of DistilBertForQuestionAnswering were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertConfig {\n",
      "  \"_name_or_path\": \"pretrained/distilbert-base-cased-distilled-squad\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.5.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "CPU times: user 3.91 s, sys: 1.83 s, total: 5.73 s\n",
      "Wall time: 3.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#pretrained_dir = \"pretrained/bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "pretrained_dir = \"pretrained/distilbert-base-cased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_dir)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(pretrained_dir, from_tf=True)\n",
    "print(repr(model.config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24b59059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 11503 to 7243\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Id            1000 non-null   object\n",
      " 1   ground_truth  1000 non-null   object\n",
      " 2   is_multi      1000 non-null   int8  \n",
      "dtypes: int8(1), object(2)\n",
      "memory usage: 24.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet(\"input/train.parquet\")\n",
    "train = train.sample(1000)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "378fb17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _inputs(tokenizer, sentences, question, max_tokens):\n",
    "    inputs = None\n",
    "    prev = None\n",
    "    _len = 0\n",
    "    tmp = []\n",
    "    while len(sentences) != 0 and _len < max_tokens:\n",
    "        prev = inputs\n",
    "        tmp.append(sentences[0])\n",
    "        passage = \" \".join(tmp)\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            question, passage,\n",
    "            truncation=\"only_second\",\n",
    "            max_length=max_tokens,\n",
    "            add_special_tokens=True, \n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        _len = len(inputs[\"input_ids\"][0])\n",
    "        if _len < max_tokens:\n",
    "            sentences.popleft()\n",
    "        #print(f\"inputs={inputs}\")\n",
    "        #print(f\"_len={_len}\")\n",
    "    if _len >= max_tokens and prev is not None:\n",
    "        inputs = prev\n",
    "    return inputs\n",
    "    \n",
    "\n",
    "def qa_predict(data_dir, model, tokenizer, question, n_window: int, \n",
    "               max_length: int = 1_000_000, max_tokens: int = 512):\n",
    "    def fn(row) -> str:\n",
    "        rid = row[\"Id\"]\n",
    "        tmp = []\n",
    "        with open(f\"{data_dir}/{rid}.json\") as in_file:\n",
    "            sections = json.load(in_file)\n",
    "            for section in sections:\n",
    "                tmp.append(section[\"text\"])\n",
    "        text = \" \".join(tmp).strip()\n",
    "        if len(text) == 0:\n",
    "            print(f\"len(text)=0, Id={rid}\")\n",
    "            return \"\"\n",
    "        if len(text) > max_length:\n",
    "            text = text[:max_length]\n",
    "        sentences: Deque[str] = Deque(snlp.sentences(text))\n",
    "        if len(sentences) == 0:\n",
    "            print(f\"len(sentences)=0, Id={rid}\")\n",
    "            return \"\"\n",
    "        res = set()\n",
    "        for _ in range(n_window):\n",
    "            if len(sentences) == 0:\n",
    "                break\n",
    "            inputs = _inputs(tokenizer=tokenizer, sentences=sentences, question=question, max_tokens=max_tokens)\n",
    "            input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "            sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "            answer_start_scores, answer_end_scores = model(**inputs).values()\n",
    "            #print(f\"answer_start_scores.shape={answer_start_scores.shape}, answer_end_scores.shape={answer_end_scores.shape}\")\n",
    "            ai = torch.argmax(answer_start_scores)\n",
    "            aj = torch.argmax(answer_end_scores) + 1\n",
    "            #print(f\"ai={ai}, aj={aj}\")\n",
    "            if ai <= sep_index:\n",
    "                continue\n",
    "            a = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[ai:aj]))\n",
    "            a = mylib.clean_text(a)\n",
    "            if len(a) < 4 or len(a) > 150:\n",
    "                continue\n",
    "            n_digits = snlp.count_digit(a)\n",
    "            if n_digits > 4 or n_digits / len(a) > 0.2:\n",
    "                continue\n",
    "            res.add(a)\n",
    "        return \"|\".join(res)\n",
    "    \n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8daf1a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [24:43<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "train[\"PredictionString\"] = train.progress_apply(\n",
    "    qa_predict(\n",
    "        data_dir=f\"input/train\",\n",
    "        #nlp=nlp,\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        question=\"name of study\",\n",
    "        #question=\"name dataset study survey program initiative\",\n",
    "        #question=\"name of dataset database study survey program initiative model assessment archive collection catalog registry\",\n",
    "        #window_length=4,\n",
    "        #stride=3,\n",
    "        n_window=6,\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed8c72f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 11503 to 7243\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Id                1000 non-null   object\n",
      " 1   ground_truth      1000 non-null   object\n",
      " 2   is_multi          1000 non-null   int8  \n",
      " 3   PredictionString  1000 non-null   object\n",
      "dtypes: int8(1), object(3)\n",
      "memory usage: 32.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe982ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>is_multi</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11503</th>\n",
       "      <td>72897d3a-7abb-486f-94da-139bfadbe40d</td>\n",
       "      <td>agricultural resource management survey</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>bf81c91c-7ef7-4e17-86d5-128baccdf0bc</td>\n",
       "      <td>early childhood longitudinal study</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>f3c6ab46-7e14-4f07-b316-ee2b708eb2e3</td>\n",
       "      <td>common core of data|nces common core of data</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>a3c6594b-854d-4ec2-b30f-7ff5ffe4ab09</td>\n",
       "      <td>ibtracs|international best track archive for climate stewardship</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>000efc17-13d8-433d-8f62-a3932fe4f3b8</td>\n",
       "      <td>adni|alzheimer s disease neuroimaging initiative adni</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Id  \\\n",
       "11503  72897d3a-7abb-486f-94da-139bfadbe40d   \n",
       "2776   bf81c91c-7ef7-4e17-86d5-128baccdf0bc   \n",
       "1508   f3c6ab46-7e14-4f07-b316-ee2b708eb2e3   \n",
       "1399   a3c6594b-854d-4ec2-b30f-7ff5ffe4ab09   \n",
       "3968   000efc17-13d8-433d-8f62-a3932fe4f3b8   \n",
       "\n",
       "                                                           ground_truth  \\\n",
       "11503                           agricultural resource management survey   \n",
       "2776                                 early childhood longitudinal study   \n",
       "1508                       common core of data|nces common core of data   \n",
       "1399   ibtracs|international best track archive for climate stewardship   \n",
       "3968             adni|alzheimer s disease neuroimaging initiative adni    \n",
       "\n",
       "       is_multi PredictionString  \n",
       "11503         0                   \n",
       "2776          0                   \n",
       "1508          1                   \n",
       "1399          1                   \n",
       "3968          1                   "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a5ca072",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet(\"output/validation.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd1de410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score=0.0467\n",
      "CPU times: user 0 ns, sys: 15.6 ms, total: 15.6 ms\n",
      "Wall time: 14.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = mylib.fbeta(y_true=train[\"ground_truth\"], y_pred=train[\"PredictionString\"])\n",
    "print(f\"score={score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ebad0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1746\n",
    "# question=\"name dataset study survey program initiative\",\n",
    "# window_length=4,\n",
    "# stride=3,\n",
    "# n_window=6,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef51dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"|\".join([]) == \"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
