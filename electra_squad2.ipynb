{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1aea8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6ffd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8a13644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='pretrained/google/electra-small-discriminator', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "['input_ids', 'token_type_ids', 'attention_mask']\n",
      "CPU times: user 15.6 ms, sys: 0 ns, total: 15.6 ms\n",
      "Wall time: 24.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pretrained_dir = \"pretrained/google/electra-small-discriminator\"\n",
    "model_max_length = 512\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_dir, model_max_length=model_max_length)\n",
    "print(f\"{repr(tokenizer)}\\n{tokenizer.model_input_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95355f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 130318 entries, 0 to 130318\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             130318 non-null  object\n",
      " 1   is_impossible  130318 non-null  int8  \n",
      " 2   question       130318 non-null  object\n",
      " 3   answer_start   130318 non-null  int16 \n",
      " 4   answer_end     130318 non-null  int16 \n",
      " 5   answer_text    130318 non-null  object\n",
      " 6   context        130318 non-null  object\n",
      "dtypes: int16(2), int8(1), object(4)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet(\"input/squad/train.parquet\")\n",
    "train.drop(index=train[train[\"id\"] == \"5acd29f507355d001abf3774\"].index, inplace=True)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1218d2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "len=130318\n",
      "CPU times: user 1min 1s, sys: 125 ms, total: 1min 1s\n",
      "Wall time: 19.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "enc = tokenizer(list(train[\"context\"]), list(train[\"question\"]))\n",
    "print(f\"{repr(enc.keys())}\\nlen={len(enc['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a9b1f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping'])\n",
      "len=130134\n",
      "CPU times: user 1min 16s, sys: 39.7 s, total: 1min 55s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "indices = []\n",
    "for i, v in enumerate(enc[\"input_ids\"]):\n",
    "    if len(v) <= model_max_length:\n",
    "        indices.append(i)\n",
    "train = train.iloc[indices]\n",
    "enc = tokenizer(list(train[\"context\"]), list(train[\"question\"]), padding=\"max_length\", return_offsets_mapping=True)\n",
    "print(f\"{repr(enc.keys())}\\nlen={len(enc['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4b0715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_positions(encodings, answer_start, answer_end, ids, is_impossible):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(is_impossible)):\n",
    "        j, k = 0, 0\n",
    "        if is_impossible[i] == 0:\n",
    "            j = encodings.char_to_token(i, answer_start[i])\n",
    "            if j is None:\n",
    "                offsets = encodings[\"offset_mapping\"][i]\n",
    "                _id = ids[i]\n",
    "                raise ValueError(f\"start pos must not be None. i={i}, id={_id}, answer_start={answer_start[i]}\\noffsets={offsets}\") \n",
    "            k = encodings.char_to_token(i, answer_end[i] - 1)\n",
    "            if k is None:\n",
    "                raise ValueError(\"end pos must not be None\")\n",
    "            if j > k:\n",
    "                raise ValueError(\"start pos must be less than or equals end pos\")\n",
    "        start_positions.append(j)\n",
    "        end_positions.append(k)\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b741f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e4f7576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 219 ms, sys: 0 ns, total: 219 ms\n",
      "Wall time: 211 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "add_token_positions(\n",
    "    enc, \n",
    "    answer_start=list(train[\"answer_start\"]), \n",
    "    answer_end=list(train[\"answer_end\"]),\n",
    "    ids=list(train[\"id\"]),\n",
    "    is_impossible=list(train[\"is_impossible\"]),\n",
    ")\n",
    "train_ds = SquadDataset(enc)\n",
    "del enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ced5229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pretrained/google/electra-small-discriminator were not used when initializing ElectraForQuestionAnswering: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at pretrained/google/electra-small-discriminator and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraConfig {\n",
      "  \"_name_or_path\": \"pretrained/google/electra-small-discriminator\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.5.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "CPU times: user 391 ms, sys: 141 ms, total: 531 ms\n",
      "Wall time: 459 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(pretrained_dir)\n",
    "print(repr(model.config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f87a9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [5:33:00<00:00, 195.89s/it] \n",
      "  0%|          | 0/102 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=2.7604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [5:31:52<00:00, 195.22s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1, loss=1.6722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "max_examples = int(0.1 * len(train_ds))\n",
    "indices = range(len(train_ds))\n",
    "indices = random.sample(indices, max_examples)\n",
    "sample_ds = Subset(train_ds, indices)\n",
    "train_loader = DataLoader(sample_ds, batch_size=128, shuffle=True)\n",
    "#train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "optim = AdamW(model.parameters(), lr=5e-4)\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    loss_mean = 0\n",
    "    steps = len(train_loader)\n",
    "    for batch in tqdm(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        outputs = model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask,\n",
    "                        start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs[0]\n",
    "        loss_mean += loss / steps\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    print(f\"epoch={epoch}, loss={loss_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "366954a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForQuestionAnswering(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1132bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c1b8fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraConfig {\n",
      "  \"_name_or_path\": \"tmp\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.5.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "CPU times: user 344 ms, sys: 15.6 ms, total: 359 ms\n",
      "Wall time: 294 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"tmp\")\n",
    "print(repr(model.config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4c52a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.sample(30)\n",
    "questions = list(df[\"question\"])\n",
    "contexts = list(df[\"context\"])\n",
    "golds = list(df[\"answer_text\"])\n",
    "is_impossible = list(df[\"is_impossible\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9ea99ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=In what year were all Tibetan Muslims declared Indiana citizens?\n",
      "c=Muslims have been living in Tibet since as early as the 8th or 9th century. In Tibetan cities, there are small communities of Muslims, known as Kachee (Kache), who trace their origin to immigrants from three main regions: Kashmir (Kachee Yul in ancient Tibetan), Ladakh and the Central Asian Turkic countries. Islamic influence in Tibet also came from Persia. After 1959 a group of Tibetan Muslims made a case for Indian nationality based on their historic roots to Kashmir and the Indian government declared all Tibetan Muslims Indian citizens later on that year. Other Muslim ethnic groups who have long inhabited Tibet include Hui, Salar, Dongxiang and Bonan. There is also a well established Chinese Muslim community (gya kachee), which traces its ancestry back to the Hui ethnic group of China.\n",
      "i=0, j=78, k=79\n",
      "a=1959\n",
      "g=1959\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=What did Apple's creation of too many similar models do to potential buyers?\n",
      "c=Furthermore, Apple had created too many similar models that confused potential buyers. At one point, its product lineup was subdivided into Classic, LC, II, Quadra, Performa, and Centris models, with essentially the same computer being sold under a number of different names. These models competed against Macintosh clones, hardware manufactured by third parties that ran Apple's System 7. This succeeded in increasing the Macintosh's market share somewhat, and provided cheaper hardware for consumers, but hurt Apple financially as existing Apple customers began to buy cheaper clones which cannibalized the sales of Apple's higher-margin Macintosh systems, yet Apple still shouldered the burden of developing the Mac OS platform.\n",
      "i=1, j=11, k=12\n",
      "a=confused\n",
      "g=confused potential buyers\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=What countries were involved in the Franco-Russian war?\n",
      "c=The Franco-Prussian War was a conflict between France and Prussia, while Prussia was backed up by the North German Confederation, of which it was a member, and the South German states of Baden, Württemberg and Bavaria. The complete Prussian and German victory brought about the final unification of Germany under King Wilhelm I of Prussia. It also marked the downfall of Napoleon III and the end of the Second French Empire, which was replaced by the Third Republic. As part of the settlement, almost all of the territory of Alsace-Lorraine was taken by Prussia to become a part of Germany, which it would retain until the end of World War I.\n",
      "i=2, j=10, k=13\n",
      "a=france and prussia\n",
      "g=France and Prussia\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=What idea did Adam Smith disagree with?\n",
      "c=The basis for classical economics forms Adam Smith's An Inquiry into the Nature and Causes of the Wealth of Nations, published in 1776. Smith criticized mercantilism, advocating a system of free trade with division of labour. He postulated an \"invisible hand\" that regulated economic systems made up of actors guided only by self-interest. Karl Marx developed an alternative economic theory, called Marxian economics. Marxian economics is based on the labor theory of value and assumes the value of good to be based on the amount of labor required to produce it. Under this assumption, capitalism was based on employers not paying the full value of workers labor to create profit. The Austrian school responded to Marxian economics by viewing entrepreneurship as driving force of economic development. This replaced the labor theory of value by a system of supply and demand.\n",
      "i=3, j=30, k=34\n",
      "a=mercantilism\n",
      "g=mercantilism\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=Who made HDTV official in 1993?\n",
      "c=HDTV technology was introduced in the United States in the late 1980s and made official in 1993 by the Digital HDTV Grand Alliance, a group of television, electronic equipment, communications companies consisting of AT&T Bell Labs, General Instrument, Philips, Sarnoff, Thomson, Zenith and the Massachusetts Institute of Technology. Field testing of HDTV at 199 sites in the United States was completed August 14, 1994. The first public HDTV broadcast in the United States occurred on July 23, 1996 when the Raleigh, North Carolina television station WRAL-HD began broadcasting from the existing tower of WRAL-TV southeast of Raleigh, winning a race to be first with the HD Model Station in Washington, D.C., which began broadcasting July 31, 1996 with the callsign WHD-TV, based out of the facilities of NBC owned and operated station WRC-TV. The American Advanced Television Systems Committee (ATSC) HDTV system had its public launch on October 29, 1998, during the live coverage of astronaut John Glenn's return mission to space on board the Space Shuttle Discovery. The signal was transmitted coast-to-coast, and was seen by the public in science centers, and other public theaters specially equipped to receive and display the broadcast.\n",
      "i=4, j=21, k=26\n",
      "a=digital hdtv grand alliance\n",
      "g=the Digital HDTV Grand Alliance\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=What's the name of the feature that would let you play a game on your PSP without having it with you?\n",
      "c=PlayStation Portable can connect with PlayStation 3 in many ways, including in-game connectivity. For example, Formula One Championship Edition, a racing game, was shown at E3 2006 using a PSP as a real-time rear-view mirror. In addition, users are able to download original PlayStation format games from the PlayStation Store, transfer and play them on PSP as well as PS3 itself. It is also possible to use the Remote Play feature to play these and some PlayStation Network games, remotely on PSP over a network or internet connection.\n",
      "i=5, j=88, k=1\n",
      "a=IMPOSSIBLE\n",
      "g=Remote Play\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=What Latin word was a misunderstanding?\n",
      "c=The English word Slav could be derived from the Middle English word sclave, which was borrowed from Medieval Latin sclavus or slavus, itself a borrowing and Byzantine Greek σκλάβος sklábos \"slave,\" which was in turn apparently derived from a misunderstanding of the Slavic autonym (denoting a speaker of their own languages). The Byzantine term Sklavinoi was loaned into Arabic as Saqaliba صقالبة (sing. Saqlabi صقلبي) by medieval Arab historiographers. However, the origin of this word is disputed.\n",
      "i=6, j=0, k=1\n",
      "a=[CLS]\n",
      "g=sclavus or slavus\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=What is the American Rule?\n",
      "c=Generally, American civil procedure has several notable features, including extensive pretrial discovery, heavy reliance on live testimony obtained at deposition or elicited in front of a jury, and aggressive pretrial \"law and motion\" practice designed to result in a pretrial disposition (that is, summary judgment) or a settlement. U.S. courts pioneered the concept of the opt-out class action, by which the burden falls on class members to notify the court that they do not wish to be bound by the judgment, as opposed to opt-in class actions, where class members must join into the class. Another unique feature is the so-called American Rule under which parties generally bear their own attorneys' fees (as opposed to the English Rule of \"loser pays\"), though American legislators and courts have carved out numerous exceptions.\n",
      "i=7, j=0, k=146\n",
      "a=[CLS] generally, american civil procedure has several notable features, including extensive pretrial discovery, heavy reliance on live testimony obtained at deposition or elicited in front of a jury, and aggressive pretrial \" law and motion \" practice designed to result in a pretrial disposition ( that is, summary judgment ) or a settlement. u. s. courts pioneered the concept of the opt - out class action, by which the burden falls on class members to notify the court that they don't wish to be bound by the judgment, as opposed to opt - in class actions, where class members must join into the class. another unique feature is the so - called american rule under which parties generally bear their own attorneys'fees\n",
      "g=parties generally bear their own attorneys' fees\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=How is God usually perceived by process theologians?\n",
      "c=Process theology typically stresses God's relational nature. Rather than seeing God as impassive or emotionless, process theologians view God as \"the fellow sufferer who understands\", and as the being who is supremely affected by temporal events. Hartshorne points out that people would not praise a human ruler who was unaffected by either the joys or sorrows of his followers – so why would this be a praise-worthy quality in God? Instead, as the being who is most affected by the world, God is the being who can most appropriately respond to the world. However, process theology has been formulated in a wide variety of ways. C. Robert Mesle, for instance, advocates a \"process naturalism\", i.e. a process theology without God.\n",
      "i=8, j=29, k=22\n",
      "a=IMPOSSIBLE\n",
      "g=\"the fellow sufferer who understands\", and as the being who is supremely affected by temporal events\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=Which country refused to send troops into Afghanistan?\n",
      "c=Support for the U.S. cooled when America made clear its determination to invade Iraq in late 2002. Even so, many of the \"coalition of the willing\" countries that unconditionally supported the U.S.-led military action have sent troops to Afghanistan, particular neighboring Pakistan, which has disowned its earlier support for the Taliban and contributed tens of thousands of soldiers to the conflict. Pakistan was also engaged in the War in North-West Pakistan (Waziristan War). Supported by U.S. intelligence, Pakistan was attempting to remove the Taliban insurgency and al-Qaeda element from the northern tribal areas.\n",
      "i=9, j=58, k=59\n",
      "a=pakistan\n",
      "g=Pakistan\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=Who was the son of Muhammad ibn Abi Bakr?\n",
      "c=Early Muslim armies stayed in encampments away from cities because Umar feared that they might get attracted to wealth and luxury. In the process, they might turn away from the worship of God and start accumulating wealth and establishing dynasties. When Uthman ibn al-Affan became very old, Marwan I, a relative of Muawiyah I, slipped into the vacuum, became his secretary, slowly assumed more control and relaxed some of these restrictions. Marwan I had previously been excluded from positions of responsibility. In 656, Muhammad ibn Abi Bakr, the son of Abu Bakr, the adopted son of Ali ibn Abi Talib, and the great grandfather of Ja'far al-Sadiq, showed some Egyptians the house of Uthman ibn al-Affan. Later the Egyptians ended up killing Uthman ibn al-Affan.\n",
      "i=10, j=127, k=96\n",
      "a=IMPOSSIBLE\n",
      "g=Ja'far al-Sadiq\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=How had the Vandals earned their strong reputation?\n",
      "c=As the Roman Empire was falling apart, Palermo fell under the control of several Germanic tribes. The first were the Vandals in 440 AD under the rule of their king Geiseric. The Vandals had occupied all the Roman provinces in North Africa by 455 establishing themselves as a significant force. They acquired Corsica, Sardinia and Sicily shortly afterwards. However, they soon lost these newly acquired possessions to the Ostrogoths. The Ostrogothic conquest under Theodoric the Great began in 488; Theodoric supported Roman culture and government unlike the Germanic Goths. The Gothic War took place between the Ostrogoths and the Eastern Roman Empire, also known as the Byzantine Empire. Sicily was the first part of Italy to be taken under control of General Belisarius who was commissioned by Eastern Emperor. Justinian I solidified his rule in the following years.\n",
      "i=11, j=0, k=38\n",
      "a=[CLS] as the roman empire was falling apart, palermo fell under the control of several germanic tribes. the first were the vandals in 440 ad under the rule of their king geiseric\n",
      "g=occupied all the Roman provinces in North Africa by 455\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=What type of scientists rely on windscreens for distant observations?\n",
      "c=In the 20th century, new types of glass such as laminated glass, reinforced glass and glass bricks have increased the use of glass as a building material and resulted in new applications of glass. Multi-storey buildings are frequently constructed with curtain walls made almost entirely of glass. Similarly, laminated glass has been widely applied to vehicles for windscreens. While glass containers have always been used for storage and are valued for their hygienic properties, glass has been utilized increasingly in industry. Optical glass for spectacles has been used since the late Middle Ages. The production of lenses has become increasingly proficient, aiding astronomers as well as having other application in medicine and science. Glass is also employed as the aperture cover in many solar energy systems.\n",
      "i=12, j=57, k=60\n",
      "a=laminated glass\n",
      "g=astronomers\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=What was Switzerland's median income in 2007?\n",
      "c=The World Economic Forum's Global Competitiveness Report currently ranks Switzerland's economy as the most competitive in the world, while ranked by the European Union as Europe's most innovative country. For much of the 20th century, Switzerland was the wealthiest country in Europe by a considerable margin (by GDP – per capita). In 2007 the gross median household income in Switzerland was an estimated 137,094 USD at Purchasing power parity while the median income was 95,824 USD. Switzerland also has one of the world's largest account balances as a percentage of GDP.\n",
      "i=13, j=77, k=82\n",
      "a=137, 094 usd\n",
      "g=95,824 USD\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=What was the date of Queen Victorias birth?\n",
      "c=Following a custom she maintained throughout her widowhood, Victoria spent the Christmas of 1900 at Osborne House on the Isle of Wight. Rheumatism in her legs had rendered her lame, and her eyesight was clouded by cataracts. Through early January, she felt \"weak and unwell\", and by mid-January she was \"drowsy ... dazed, [and] confused\". She died on Tuesday, 22 January 1901, at half past six in the evening, at the age of 81. Her son and successor King Edward VII, and her eldest grandson, Emperor Wilhelm II of Germany, were at her deathbed. Her favourite pet Pomeranian, Turri, was laid upon her deathbed as a last request.\n",
      "i=14, j=89, k=92\n",
      "a=22 january 1901\n",
      "g=22 January 1901\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=Who conducted the review on Thiazide Antihypertensive drugs?\n",
      "c=A 2009 Cochrane review concluded that thiazide antihypertensive drugs reduce the risk of death (RR 0.89), stroke (RR 0.63), coronary heart disease (RR 0.84), and cardiovascular events (RR 0.70) in people with high blood pressure. In the ensuring years other classes of antihypertensive drug were developed and found wide acceptance in combination therapy, including loop diuretics (Lasix/furosemide, Hoechst Pharmaceuticals, 1963), beta blockers (ICI Pharmaceuticals, 1964) ACE inhibitors, and angiotensin receptor blockers. ACE inhibitors reduce the risk of new onset kidney disease [RR 0.71] and death [RR 0.84] in diabetic patients, irrespective of whether they have hypertension.\n",
      "i=15, j=0, k=1\n",
      "a=[CLS]\n",
      "g=Cochrane\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=How do some countries members maintain self-preservation?\n",
      "c=Although NPOs are permitted to generate surplus revenues, they must be retained by the organization for its self-preservation, expansion, or plans. NPOs have controlling members or a board of directors. Many have paid staff including management, whereas others employ unpaid volunteers and even executives who work with or without compensation (occasionally nominal). In some countries, where there is a token fee, in general it is used to meet legal requirements for establishing a contract between the executive and the organization.\n",
      "i=16, j=0, k=1\n",
      "a=[CLS]\n",
      "g=a token fee\n",
      "\n",
      "\n",
      "is_impossible=0\n",
      "q=What regime were Hussein loyalists part of?\n",
      "c=The first ground attack came at the Battle of Umm Qasr on 21 March 2003 when a combined force of British, American and Polish forces seized control of the port city of Umm Qasr. Baghdad, Iraq's capital city, fell to American forces in April 2003 and Saddam Hussein's government quickly dissolved. On 1 May 2003, Bush announced that major combat operations in Iraq had ended. However, an insurgency arose against the U.S.-led coalition and the newly developing Iraqi military and post-Saddam government. The insurgency, which included al-Qaeda affiliated groups, led to far more coalition casualties than the invasion. Other elements of the insurgency were led by fugitive members of President Hussein's Ba'ath regime, which included Iraqi nationalists and pan-Arabists. Many insurgency leaders are Islamists and claim to be fighting a religious war to reestablish the Islamic Caliphate of centuries past. Iraq's former president, Saddam Hussein was captured by U.S. forces in December 2003. He was executed in 2006.\n",
      "i=17, j=143, k=147\n",
      "a=ba'ath\n",
      "g=Ba'ath\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=How many Lemkos were expelled in Operation Vistula?\n",
      "c=Representatives of the Polish government officially took over the civilian administration of the southern part of East Prussia on 23 May 1945. Subsequently Polish expatriates from Polish lands annexed by the Soviet Union as well as Ukrainians and Lemkos from southern Poland, expelled in Operation Vistula in 1947, were settled in the southern part of East Prussia, now the Polish Warmian-Masurian Voivodeship. In 1950 the Olsztyn Voivodeship counted 689,000 inhabitants, 22.6% of them coming from areas annexed by the Soviet Union, 10% Ukrainians, and 18.5% of them pre-war inhabitants. The remaining pre-war population was treated as Germanized Poles and a policy of re-Polonization was pursued throughout the country Most of these \"Autochthones\" chose to emigrate to West Germany from the 1950s through 1970s (between 1970 and 1988 55,227 persons from Warmia and Masuria moved to Western Germany). Local toponyms were Polonised by the Polish Commission for the Determination of Place Names.\n",
      "i=18, j=0, k=1\n",
      "a=[CLS]\n",
      "g=689,000\n",
      "\n",
      "\n",
      "is_impossible=1\n",
      "q=Who likes to divide their projects into relevent time periods and geographic regions?\n",
      "c=Along with dividing up their project by theoretical emphasis, anthropologists typically divide the world up into relevant time periods and geographic regions. Human time on Earth is divided up into relevant cultural traditions based on material, such as the Paleolithic and the Neolithic, of particular use in archaeology.[citation needed] Further cultural subdivisions according to tool types, such as Olduwan or Mousterian or Levalloisian help archaeologists and other anthropologists in understanding major trends in the human past.[citation needed] Anthropologists and geographers share approaches to Culture regions as well, since mapping cultures is central to both sciences. By making comparisons across cultural traditions (time-based) and cultural regions (space-based), anthropologists have developed various kinds of comparative method, a central part of their science.\n",
      "i=19, j=0, k=1\n",
      "a=[CLS]\n",
      "g=anthropologists\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(contexts, questions, truncation=\"only_first\", padding=\"max_length\", return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "start_logits, end_logits = model(**inputs).values()\n",
    "for i in range(len(start_logits)):    \n",
    "    j = torch.argmax(start_logits[i])  \n",
    "    k = torch.argmax(end_logits[i]) + 1\n",
    "    a = \"IMPOSSIBLE\"\n",
    "    if j < k:\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids[i][j:k])\n",
    "        a = tokenizer.convert_tokens_to_string(tokens)\n",
    "    print(f\"\\n\\nis_impossible={is_impossible[i]}\\nq={questions[i]}\\nc={contexts[i]}\\ni={i}, j={j}, k={k}\\na={a}\\ng={golds[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e294bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
